# 0计算机硬件组成

### 0电脑组装

#### 0.1 CPU

> 同样定位的前提下，AMD 的综合性能会强上一筹，Intel 的游戏性能略微胜出，但是 AMD 的价格却又低了一点， AMD，YES！但是，如果你只是一个臭打游戏的，那我还是比较建议你购买 intel 的U，配上老黄的显卡，这可能还是目前最稳妥的打游戏解决方案。
>
> 以主流的**intel 酷睿系列**和**AMD 的锐龙系列**来说，它们的产品定位由低至高依次为
>
> ![img](https://s2.loli.net/2022/05/01/PixBvK3Z85RA7aL.png)
>
> 对于黑苹果：Intel的CPU和AMD的显卡（蓝宝石5700XT）超白金，没有需求尽量选择NV的显卡。
>
> CPU：Intel酷睿i7-10700K

#### 0.2 显卡

##### **0.2.1显卡是什么**？

![image-20220501145300669](https://s2.loli.net/2022/05/01/x7rBL1AovtwJ5aQ.png)

![image-20220501145247372](https://s2.loli.net/2022/05/01/2ETOULthuH3w8Bk.png)

显卡，是由**GPU、显存、电路板，还有BIOS固件组成的**，所以GPU不等于显卡。

GPU就是图像处理芯片，外表与CPU有点相似。GPU是显卡上的一个核心处理芯片，是AMD的一个技术。相当于电脑的处理器CPU，只不过它是显卡的大脑或心脏。

显卡分为核心显卡和独立显卡。核心显卡集成在CPU内，独立显卡则是与CPU独立的硬件。

> GPU全称是Graphic Processing Unit，中文翻译为“图形处理器”。NVIDIA公司在发布GeForce 256图形处理芯片时首先提出的概念。GPU使显卡减少了对CPU的依赖，并进行部分原本CPU的工作，尤其是在3D图形处理时。GPU所采用的核心技术有硬件T&L(几何转换和光照处理)、立方环境材质贴图和顶点混合、纹理压缩和凹凸映射贴图、双重纹理四像素256位渲染引擎等，而硬件T&L技术可以说是GPU的标志。GPU的生产主要由nVidia与ATI两家厂商生产。

**显存**

　　显存是显示内存的简称(类似于主板的内存)。其主要功能就是暂时将储存显示芯片要处理的数据和处理完毕的数据。图形核心的性能愈强，需要的显存也就越多。以前的显存主要是SDR的，容量也不大。市面上的显卡大部分采用的是G[DDR3显存](https://product.pconline.com.cn/itbk/diy/graphics/1112/2624084.html)，现在最新的显卡则采用了性能更为出色的[GDDR4](https://product.pconline.com.cn/itbk/diy/graphics/1111/2579000.html)或[GDDR](https://product.pconline.com.cn/itbk/diy/graphics/1112/2628133.html)5显存。一般来讲越大越好，不过一般都是匹配显卡型号来的，也没啥可选择的。



**显卡[BIOS](https://product.pconline.com.cn/itbk/diy/mb/1107/2474316.html)**

　　显卡BIOS(类似于主板的BIOS)主要用于存放显示芯片与驱动程序之间的控制程序，另外还存有显示卡的型号、规格、生产厂家及出厂时间等信息。打开计算机时，通过显示BIOS 内的一段控制程序，将这些信息反馈到屏幕上。早期显示BIOS 是固化在ROM 中的，不可以修改，而多数显示卡则采用了大容量的EPROM，即所谓的Flash BIOS，可以通过专用的程序进行改写或升级。

**显卡PCB板**

　　就是显卡的电路板(类似于主板的PCB板)，它把显卡上的其它部件连接起来。功能类似主板。　　显卡分类集成显卡　　集成显卡是将显示芯片、显存及其相关电路都做在主板上，与主板融为一体;集成显卡的显示芯片有单独的，但大部分都集成在主板的[北桥芯片](https://product.pconline.com.cn/itbk/diy/mb/1107/2473941.html)中;一些主板集成的显卡也在主板上单独安装了显存，但其容量较小，集成显卡的显示效果与处理性能相对较弱，不能对显卡进行硬件升级，但可以通过CMOS调节频率或刷入新BIOS文件实现软件升级来挖掘显示芯片的潜能。



##### 0.2.2**选购**：

主流显卡的显示芯片主要由NVIDIA（英伟达）和AMD（超微半导体）两大厂商制造，通常将采用NVIDIA显示芯片的显卡称为N卡，而将采用AMD显示芯片的显卡称为A卡，是显卡的两大阵营。

![preview](https://s2.loli.net/2022/05/01/ncw8WdlzAhMCYB5.jpg)

**显卡的品牌，哪个牌子的显卡好？**

**卡显卡品牌**

![img](https://pic2.zhimg.com/v2-0eb98eb241c1a76122ff6e1d89db366d_b.jpg)

**A卡显卡品牌**

![img](https://pic4.zhimg.com/v2-71b2e87c215876be1fcfbaeb91f8d3db_b.jpg)

现在显卡市场NVIDIA（英伟达）有绝对优势，在高端顶级显卡市场更是没有对手。

现阶段的显卡市场，建议选购N卡，各种软件优化好，更稳定，性能更强。如果要组“黑苹果”的除外，因为黑苹果A卡免驱动。

**显卡型号及后缀：**

RTX前缀的是30系列的显卡，如RTX 3060、RTX 3070、RTX 3080、RTX 3090、是目前最新最高级的系列，支持光线追踪，后面的数字60、70、80，性能90>80>70>60,可以简单理解数越大强，下面的10系列同理。

GTX前缀的主要是10系列，如GTX1650、1650Super、1660、1660Super，定位比RTX级别低，价格也更亲民。

后缀Super（一般缩写为S）如1660S，这个是带S的是“超级”的意思，上1660产品的升级版本。另外还能看到后缀加Ti的，如2080Ti，后缀Ti的意思加强版。性能排序RTX 2080Ti>RTX 2080S>RTX 2080，还是比较好理解的。

AMD显卡中RX 6800和RX 6800XT，后缀XT代表加强版的意思，性能RX 6800XT>RX 6800.

**具体产品推荐**：

**入门独立显卡：（800元~1300元）**

- N卡型号：GTX 1650、GTX1650S
- A卡型号：RX 6500XT

**中端主流显卡：（1500元~2300元）**

- N卡型号：RTX3050
- A卡型号：RX 6600、RX 6600XT

**高端旗舰显卡：（2500元~20000元）**

- N卡型号：RTX3060、RTX3060Ti、RTX3070/Ti、RTX3080/Ti、RTX3090/Ti
- A卡型号：RX6600、RX6600XT、RX6700XT、RX6800、RX6800XT、RX6900XT

![img](https://s2.loli.net/2022/05/01/Axui76ByRVceEs5.jpg)



#### 0.3 主板

##### **0.3.1 主板的定义**

主板就是PC（个人计算机）中最重要的硬件组成部分。英语：Motherboard, 又称主机板、系统板、逻辑板、母板、底板等，是构成复杂电子系统例如电子计算机的中心或者主电路板

主板一般为矩形的电路板，上面安装了组成计算机的主要电路系统，一般有**BIOS芯片**、**I/O输入输出控制芯片**、**键盘**和**面板控制开关接口**、指示灯插接件、扩充插槽等元件

##### **0.3.2 主板的版型**

![preview](https://s2.loli.net/2022/05/01/mkhn3zViQtWALMH.png)

##### **0.3.3 芯片组** 

芯片组简单的说，芯片组是主板最重要的一颗集成芯片，他决定了主板可以使用什么CPU，可以具有多少原生接口和扩展能力

那么该如何选购芯片组呢？

同样芯片组的比价格，同样价格的比做工用料，同样做工的比BIOS，比较常见的芯片组有100、200和300型分别搭配6，7和8代CPU

其系列分为B,H,Z系列，分别代表的是入门，中端，高端

##### **0.3.4了解主板的重要插槽**

**1.CPU插槽**

顾名思义，所有主板都会采用的插槽，主要用途是安装CPU，目前主要分为两种，英特尔插槽和AMD插槽

英特尔插槽：插针是在主板上，要保护好主板上的插针

![img](https://pic4.zhimg.com/v2-d72d27e325490d0c50b4551a64ff62a7_b.jpg)

AMD插槽：插针是在CPU上，要保护好CPU上的插针

![img](https://pic3.zhimg.com/v2-fc1f905e862f1deff3147fe3e23c668a_b.jpg)



**2.内存插槽**

顾名思义，就是安装内存用的插槽。内存也是PC的重要部件之一

内存插槽中间有一个防呆口，这个防呆口的作用是保证内存正确的安装方向和保证安装正确的内存类型，注意在安装内存时绝对不可以使用蛮力

现在还在较多使用的内存分为DDR3\DDR4，这两者是不可以混插的，其频率也分为2133/2400/3000等等，选择主板的时候也要选择对应的内存接口和频率

![img](https://pic3.zhimg.com/v2-e2e79445f5276e1b27e3c2c012fc618a_b.jpg)

##### **0.3.5了解主板的接口**

**1.USB接口**

USB接口是现在使用最广泛的主板接口，几乎每一个使用电子产品的人都会用来外接鼠标，键盘，U盘，移动硬盘等设备

USB接口目前主要分为2.0和3.0还有3.1三种规范。2.0接口的标称速度是480Mbps，也就是60MB\s；3.0接口的标称速度是5Gbps，也就是500MB\s。3.1接口的标称速度是10Gbps，也就是1000MB\s，当然这个仅仅是接口的标称速度，实际的话一般不太可能跑满

**2.USB后窗接口**

在主板的后窗上USB接口的外观大家应该已经非常熟悉了。一般USB接口的内部一般都有会有颜色，蓝色的通常就是USB 3.0接口，黑色或其他颜色的就是USB 2.0接口。如果USB接口被标识为红色，一般都代表会有一些主板厂商特色技术，比如快速充电等技术

![img](https://pic4.zhimg.com/v2-b0d80bb323f3bbeb5c843798819f554f_b.jpg)

**3.显示接口**

显示接口的作用是主板上用来输出视频信号的接口。常见显示接口的名称和分类见下图：

![img](https://pic1.zhimg.com/v2-aa49153a918a9591a7ae67bec4f5ecb4_b.jpg)

下面两张图片就是常见接口的形状，有助于你们区别，有需要的可以保存收藏起来，其中DVI-D与DVI-I的区别就是在接口右边，D是一根沟槽，I是一个十字

![img](https://pic3.zhimg.com/v2-4727cda23ee73ea94343c79481f17706_b.jpg)

![img](https://pic4.zhimg.com/v2-b18eeabbd2085a721ef3d9f06d88fae7_b.jpg)

**4.网线接口**

网线接口就是用来连接网线与电脑，实现网络连接的接口，一般上方会有两个指示灯，接入成功后网线上的水晶头会亮起，接口图可以参考下图

![img](https://pic4.zhimg.com/v2-85b4b26f113719e6b66ff258fa968b07_b.jpg)



#### 0.4 内存

**内存条是什么**

内存条是CPU可通过总线寻址，并进行读写操作的电脑部件。或者可以理解内存条是CPU连接其他设备的重要通道。

![img](https://pic2.zhimg.com/v2-d13230f5d23b182b43a5c195e02c7c29_b.png)





简单来说，CPU要运行程序需要从硬盘调取，但硬盘又有距离，所以需要用内存条来做一个连接。



![img](https://pic4.zhimg.com/v2-524f895927191348e03b70eca60e01e7_b.png)

![preview](https://pic4.zhimg.com/v2-39a0c98765922ae69cf9b57e7200d2bf_r.jpg)



#### 05 硬盘

#### **06 电源**

up主：硬件茶谈

### 1 CPU组成

CPU内部主要由运算器、控制器、寄存器三大部分组成。

**运算器** 负责算术运算（+ - * / 基本运算和附加运算）和逻辑运算（包括 移位、逻辑测试或比较两个值等）。
**控制器** 负责应对所有的信息情况，调度运算器把计算做好。
**寄存器** 它们可用来暂存指令、数据和地址。既要对接控制器的命令，传达命令给运算器；还要帮运算器记录处理完或者将要处理的数据。

![CPU组成](https://s2.loli.net/2022/05/01/k6fx3W8thGrw7Vi.png)

众所周知，计算机只能识别 1 和 0，为什么呢？根本原因在于 CPU 或者说所有的电子元件，只能有两种状态：变(1)、不变(0)/ 开（1）、关（0） 。但是知道这个和 CPU 有什么关系呢，CPU 的根本任务就是**执行指令预算**，也就是01010101010101001这个过程到底是怎样实现的呢。这就要从 CPU 的内部结构开始说起了:

![img](https://s2.loli.net/2022/05/01/DPbajSYiGesFprZ.png)

cpu 内部主要是由一大堆的**运算器、控制器、寄存器**组成。

![img](https://s2.loli.net/2022/05/01/SjWfnbeomCg9qZM.png)

在这三种元件外，还有**缓存（cache），总线，核心显卡**等

![img](https://s2.loli.net/2022/05/01/REDgGI8qvKF4kx1.png)

![img](https://s2.loli.net/2022/05/01/96ZvTsMx8Wlrykj.png)

#### 1.1 控制器

控制器由程序计数器（PC，Program Counter）、指令寄存器（IR，Instruction Register）、指令译码器（ID，Instruction Decoder）、时序产生器（Timing Generator）、操作控制器（Control Unit）组成。
`指令寄存器IR`，是用来存放当前正在执行的的一条指令，存放的内容来自于数据寄存器（DR，Data Register）。当一条指令需要被执行时，先要把它从内存取到数据寄存器，然后再送到指令寄存器IR中。
`指令译码器ID`，在计算机执行一条指定的指令时，必须首先分析这条指令的操作码是什么，以决定操作的性质和方法，然后控制计算机的其他各部件协同完成指令表达的功能，这中间的分析工作就是指令译码器ID完成的。
`程序计数器PC`，用来存放下一条要执行指令的地址，它与存储器（内存）之间有一条直接通路。执行指令时，首先需要根据程序计数器PC中存放的指令地址，将指令由内存取到指令寄存器IR，完成“取指令”的操作。程序计数器PC本身具有自动加1的功能，可以自动给出下一条指令的地址，如此循环，执行每一条指令。
`时序产生器`，类似于“时间作息表”，给计算机各部分提供工作所需的时间标志，一般是利用定时脉冲的顺序和不同的脉冲间隔来实现。
`操作控制器`，根据指令所需完成的操作和信号，发出各种微操作命令序列，用以控制所有被控对象，完成指令的执行。
整个控制器的运行逻辑是先按照`程序计数器`所指出的指令地址，从内存中取出一条指令到`指令寄存器IR`，然后`指令译码器ID`对指令进行分析，之后`操作控制器`根据指令的功能向有关部件发出控制命令，执行控制指令的操作。完成操作之后，`程序计数器`加1，再重复执行上述操作。

#### 1.2 运算器

运算器，一般最少包括3个`寄存器`和1个`算术逻辑单元(ALU)`，现代计算机内部往往设有通用寄存器组。

寄存器，一种有限存储容量的高速存储部件，可用来暂存指令、数据和位址。寄存器有很多种类，一般涉及到四则运算的有3类，ACC（Accumulator）为累加器，MQ（Multiplier-Quotient Register）为乘商寄存器，X为操作数寄存器，3类寄存器在完成不同运算时，所存放的操作数类别也各不相同。

![运算器](https://img2020.cnblogs.com/blog/689056/202112/689056-20211212154928359-49997161.png)

关于乘积高位和乘积低位的概念，以十进制为例，百位就是十位的高位，十位是百位的低位。两个16位数相乘，结果可能会有32位，那左半部分的16位就是乘积高位，存储到ACC中，右半部分的16位就是乘积低位，存储到MQ中。
算术逻辑单元（ALU，Arithmetic and Logic Unit），是算术运算和逻辑运算的部件。算术运算包括加、减、乘的整数运算，逻辑运算是与、或、非和异或等逻辑操作，还有移位、比较和传送等操作。
移位运算，将一个字符向左或向右移动位，或是浮动特定位，包含带符号延伸和无符号延伸，在程序中应用很广泛。

#### 1.3 寄存器

在CPU中至少要有六类寄存器：指令寄存器（IR）、程序计数器（PC）、地址寄存器（AR）、数据寄存器（DR）、累加寄存器（AC）、程序状态字寄存器（PSW）。这些寄存器用来暂存一个计算机字，其数目可以根据需要进行扩充。

1. 数据寄存器
   数据寄存器（Data Register，`DR`）又称数据缓冲寄存器，其主要功能是作为CPU和主存、外设之间信息传输的中转站，用以弥补CPU和主存、外设之间操作速度上的差异。
   数据寄存器用来暂时存放由主存储器读出的一条指令或一个数据字；反之，当向主存存入一条指令或一个数据字时，也将它们暂时存放在数据寄存器中。
   数据寄存器的作用是 ：
   （1）作为CPU和主存、外围设备之间信息传送的中转站；
   （2）弥补CPU和主存、外围设备之间在操作速度上的差异；
   （3）在单累加器结构的运算器中，数据寄存器还可兼作操作数寄存器。
2. 指令寄存器
   指令寄存器（Instruction Register，`IR`）用来保存当前正在执行的一条指令。
   当执行一条指令时，首先把该指令从主存读取到数据寄存器中，然后再传送至指令寄存器。
   指令包括操作码和地址码两个字段，为了执行指令，必须对操作码进行测试，识别出所要求的操作，指令译码器（Instruction Decoder，ID）就是完成这项工作的。指令译码器对指令寄存器的操作码部分进行译码，以产生指令所要求操作的控制电位，并将其送到微操作控制线路上，在时序部件定时信号的作用下，产生具体的操作控制信号。
   指令寄存器中操作码字段的输出就是指令译码器的输入。操作码一经译码，即可向操作控制器发出具体操作的特定信号。
3. 程序计数器
   程序计数器（Program Counter，`PC`）用来指出下一条指令在主存储器中的地址。
   在程序执行之前，首先必须将程序的首地址，即程序第一条指令所在主存单元的地址送入PC，因此PC的内容即是从主存提取的第一条指令的地址。
   当执行指令时，CPU能自动递增PC的内容，使其始终保存将要执行的下一条指令的主存地址，为取下一条指令做好准备。若为单字长指令，则(PC)+1àPC，若为双字长指令，则(PC)+2àPC，以此类推。
   但是，当遇到转移指令时，下一条指令的地址将由转移指令的地址码字段来指定，而不是像通常的那样通过顺序递增PC的内容来取得。
   因此，程序计数器的结构应当是具有寄存信息和计数两种功能的结构。
4. 地址寄存器
   地址寄存器（Address Register，`AR`）用来保存CPU当前所访问的主存单元的地址。
   由于在主存和CPU之间存在操作速度上的差异，所以必须使用地址寄存器来暂时保存主存的地址信息，直到主存的存取操作完成为止。
   当CPU和主存进行信息交换，即CPU向主存存入数据/指令或者从主存读出数据/指令时，都要使用地址寄存器和数据寄存器。
   如果我们把外围设备与主存单元进行统一编址，那么，当CPU和外围设备交换信息时，我们同样要使用地址寄存器和数据寄存器。
5. 累加寄存器
   累加寄存器通常简称累加器（Accumulator，`AC`），是一个通用寄存器。
   累加器的功能是：当运算器的算术逻辑单元ALU执行算术或逻辑运算时，为ALU提供一个工作区，可以为ALU暂时保存一个操作数或运算结果。
   显然，运算器中至少要有一个累加寄存器。
6. 程序状态字寄存器
   程序状态字（Program Status Word，`PSW`）用来表征当前运算的状态及程序的工作方式。
   程序状态字寄存器用来保存由算术/逻辑指令运行或测试的结果所建立起来的各种条件码内容，如运算结果进/借位标志（C）、运算结果溢出标志（O）、运算结果为零标志（Z）、运算结果为负标志（N）、运算结果符号标志（S）等，这些标志位通常用1位触发器来保存。
   除此之外，程序状态字寄存器还用来保存中断和系统工作状态等信息，以便CPU和系统及时了解机器运行状态和程序运行状态。
   因此，程序状态字寄存器是一个保存各种状态条件标志的寄存器。

注意：
MAR/MDR 在CPU中
MAR（memory address register，主存地址寄存器地址寄存器）的作用是：用来存放预访问的存储单元的地址，其位数对应存储单元的个数。
MDR（memory data register，主存数据寄存器，数据寄存器）的作用是：是存储器数据寄存器，用来存放从存储体某单元取出的代码。





# 6 存储器层次结构

存储器系统(memory system)是一个具有不同容量、成本和访问时间的存储设备的层次结构。CPU 寄存器保存着最常用的数据。靠近 CPU 的小的、快速的高速缓存存储器(cache memory)作为一部分存储在相对慢速的主存储器(main memory)中的数据和指令的缓冲区域。主存暂时存放在容量较大的、慢速磁盘上的数据，而这些磁盘常常又作为存储在通过网络连接的其他机器的磁盘或磁带上的区域的缓冲区域。

具有良好局部性的程序倾向于一次又一次地访问相同的数据项集合，或者是倾向于访问邻近的数据项集合。

多个具有不同容量、成本和访问时间的存储设备构成了**存储器层次结构**，称为**存储器系统**。

执行指令时访问数据所需的周期数：

1. CPU寄存器：0个周期
2. L1~L3高速缓存：4~75个周期
3. 主存：上百个周期
4. 磁盘：几千万个周期

## 6.1 存储技术

**几种基本的存储技术**

1. **随机访问存储器**，分为两类：

2. 1. **RAM**，同时也是**易失性存储器**，也分为两类：

   2. 1. **SRAM**：静态随机访问存储器，速度快，价格高。多用来作为高速缓存存储器。
      2. **DRAM**：动态随机访问存储器，速度慢，价格低。多用来作为主存和图形系统的帧缓冲器

   3. **ROM**，同时也是**非易失性存储器**。**闪存**属于 ROM，**固态硬盘**就是基于闪存开发而来。

3. 机械硬盘

4. 固态硬盘（SSD）

### 6.1.1 随机访问存储器

随机访问存储器 (Random-Access Memory, RAM)分为两类：静态的和动态的。SRAM 比 DRAM 更快，但也贵得多。SRAM 用来作为高速缓存存储器，既可以在 CPU 芯片上，也可以在片下。DRAM 用来作为主存以及图形系统的帧缓冲区。

**1、SRAM**

SRAM 将每个位存储在一个双稳态的存储器单元内。每个单元由六个晶体管组成。

双稳态即该电路无限期地稳定保持在两个不同的电压状态。

对于 SRAM，只要有电，就永远地保持它的值。即使有干扰，当干扰消除，电路也会恢复到稳定值。

**2、DRAM**

DRAM 将每个位存储为对一个电容的充电。每个 DRAM 单元由一个电容和一个访问晶体管组成。

DRAM 对干扰非常敏感。当电容的电压被扰乱后，就永远不会恢复了。

**3、SRAM和DRAM的区别**

只要有电源，SRAM是持续的。与DRAM不同，不需要刷新。SRAM的存取比DRAM快。SRAM对诸如光和电噪声之类的干扰不敏感。其代价是SRAM电池比DRAM电池使用更多的晶体管，因此密度更低，价格更贵，消耗更多电力。

![image-20220506160959027](https://s2.loli.net/2022/05/06/m5CIqYQXKcMZgOf.png)

**4、传统的 DRAM**

DRAM 芯片被分为 d 个超单元，每个超单元包含 w 个 DRAM 单元，w 一般为 8。当从 DRAM 中读取数据时，一次可以读取一个超单元的数据（可以近似的将超单元理解为一个字节）。

DRAM 中的超单元按行列组织，DRAM 中还包含一个行缓冲区。

**内存控制器** **依次**将行地址和列地址发送给 DRAM，DRAM 将对应的超单元的内容发回给内存控制器以实现读取数据。

行地址和列地址共享相同的 DRAM 芯片地址引脚。

![image-20220506162802433](https://s2.loli.net/2022/05/06/q4HjUwednvJBWAK.png)

**从 DRAM 中读取超单元的步骤：**

1. 内存控制器发来行地址 i，DRAM 将整个第 i 行复制到内部的行缓冲区。
2. 内存控制器发来列地址 i，DRAM 从行缓冲区中复制出超单元 (i,j) 并发送给内存控制器。

![image-20220506162915189](https://s2.loli.net/2022/05/06/byWis1uH8FIBPkR.png)

**5、内存模块**

许多 DRAM 芯片封装在**内存模块**中，插到主板的扩展槽上。

常用的是**双列直插内存模块 (DIMM)，以 64 位为块与内存控制器交换数据**。

比如一个内存模块包含 8 个 DRAM 芯片，每个 DRAM 包含 8M 个超单元，每个超单元存储一个字节（8bit）。**使用 8 个 DRAM 芯片上相同地址处的超单元来表示一个 64 位字**，DRAM 0 存储第一个字节，DRAM 1 存储第 2 个字节，依此类推。

要取出内存地址 A 处的一个字，内存控制器先将 A 转换为一个超单元地址 (i,j)，然后内存模块将 i,j 广播到每个 DRAM。作为响应，每个 DRAM 输出它的 (i,j) 超单元的 8 位内容，合并成一个 64 位字，再返回给内存控制器。

主存由多个内存模块连接到内存控制器聚合成。

![image-20220506165420823](https://s2.loli.net/2022/05/06/iGR7WzclrCwB1Dv.png)

![image-20220506165359774](https://s2.loli.net/2022/05/06/4AKBRfjX6mgVU2H.png)

**6、增强的 DRAM**

有一些经过优化的 DRAM：

1. **快页模式 DRAM (FPM DRAM)**：当连续访问位于同一行的超单元时，第二次以后，FPM DRAM 可以直接从行缓冲区获取数据。
2. **扩展数据输出 DRAM (EDO DRAM)**：FPM DRAM 的一个增强的形式，更快一些。
3. **同步 DRAM (****SDRAM****)**：常规的、FPM 和 EDO 都是异步的。从效果而言，SDRAM 可以比异步存储器更快地输出它的超单元的内容。 
4. **双倍数据速率同步 DRAM(DDR SDRAM)**：对 SDRAM 的一种增强，使速度翻倍。不同的 DDR SDRAM 以提高有效带宽的很小的预留缓冲区的大小来划分：DDR(2位)、DDR2(4位)、DDR3(8位)。位越多速度越快，近乎翻倍。
5. **视频 RAM (VRAM)**：用在图形系统的帧缓冲区中，其思想与 FPM DRAM 类似。VRAM 允许对内存进行并行地读和写。因此系统可以在写下一次更新的新值时（写），用帧缓冲区的像素刷屏幕（读）。

现在计算机使用的大多数都是 **DDR3 SDRAM**。

**7、非易失性存储器**

DRAM 和 SRAM 会在断电后丢失信息，因此是易失性存储器。**ROM** 是非易失性存储器，在断电后仍保存着信息。

ROM 是只读存储器，但是实际上有些 ROM 既可以读也可以写。

**几种常见的非易失性存储器：**

1. **可编程 ROM (PROM)**：只能被编程一次。
2. **可擦写可编程 ROM (EPROM)**：可以被擦除和重编程上千次。
3. **电子可擦除 PROM (EEPROM)**：类似于 EPROM，但是可以被重编程十万次。
4. **闪存**：基于 EEPROM 的一种存储技术。闪存无处不在，**固态硬盘就是一种基于闪存的磁盘驱动器**。

存储在 ROM 设备中的程序通常称为**固件**，当计算机系统通电后，会运行存储在 ROM 中的固件。

**8、访问主存**

数据流通过**总线**在处理器与主存间来往，每次处理器和主存间的数据传送的一系列步骤称为**总线事务**。

总线是一组并行的导线，能携带地址、数据和控制信号。

**系统总线**连接 CPU 和 IO 桥接器，**内存总线**连接 IO 桥接器和主存。IO 桥同时也连接着 **I/O 总线**。

![image-20220508111246708](https://s2.loli.net/2022/05/08/icqNMhI73QxEsln.png)

**读事务**的三个步骤：

1. CPU 将地址 A 放到内存总线上。
2. 主存从总线读出 A，取出字 x，然后将 x 放到总线上。
3. CPU 从总线读出字 x，并将它复制到相应寄存器中。

![image-20220508111126882](https://s2.loli.net/2022/05/08/A43Zrpq8atodPbh.png)

**写事务**的三个步骤：

1. CPU 将地址 A 放到内存总线。主存读出这个地址，并等待数据字。
2. CPU 将数据字 y 放到总线上。
3. 主存从总线读数据字 y，并将它存储在地址 A。

![image-20220508111145429](https://s2.loli.net/2022/05/08/cz3A2extWRgDb5S.png)

### 6.1.2 磁盘存储

**1、磁盘构造**

![image-20220508162615557](https://s2.loli.net/2022/05/08/jeIP56wEDQurb7Y.png)

磁盘由**盘片**组成，每个盘片有两个**表面**（上面和下面），表面上覆盖着**磁性记录材料**。一个磁盘包含一个或多个盘片。

每个表面由一系列同心圆（称为**磁道**）组成，每个磁道被划分为一组**扇区**，每个扇区包含相同的数据位（一般为512字节）。扇区之间由**间隙**分隔开，间隙中不存储数据位，而存储用来标识扇区的格式化位。如下图a。

![https://note.youdao.com/yws/public/resource/1cbaebb119458e1d6043099a42e3db7c/xmlnote/F94A1AD8503F4306A32BD130A6F02A47/40196](https://note.youdao.com/yws/public/resource/1cbaebb119458e1d6043099a42e3db7c/xmlnote/F94A1AD8503F4306A32BD130A6F02A47/40196)

名词**柱面**用来表示距离主轴相等的磁道的集合。比如一个磁盘有 3 个盘片，那么每个柱面就有 6 个磁道。如上图b。

**2、磁盘容量**

磁盘容量：一个磁盘能够存储的最大位数，由以下因素决定：

1. **记录密度**：单独决定一个扇区可以存储多少bit(或者至少是磁道的一部分)
2. **磁道密度**：相邻的磁道可以放置得多临近。
3. **面密度**：记录密度与磁道密度的乘积。决定了整个磁盘的存储容量。

磁盘容量公式：

​    ![0](https://note.youdao.com/yws/public/resource/1cbaebb119458e1d6043099a42e3db7c/xmlnote/1B6F2E65ECF847B8A78E217C0588F2E9/40200)

磁盘容量=每个扇区的字节数 * 每个磁道上的平均扇区数 * 每个盘面的平均磁道数 * 一个盘片的盘面数 * 磁盘中盘片的数量

例如，假设我们有一个带有5个磁盘的磁盘，每个扇区512字节，每个表面20,000个磁道，每个磁道平均300个扇区。则磁盘的容量为：

![image-20220508193842524](https://s2.loli.net/2022/05/08/3HCM7Jh5FDO9nPr.png)

注意，制造商表示磁盘容量的单位是GB (GB)或TB (TB)，其中1GB = 10^9字节，1tb = 10^12字节。

DRAM 和 SRAM 相关的单位中 K = 2^10，磁盘、网络、速率、吞吐量相关的单位中 K=10^3。

注：磁盘格式化会填写间隙、标识出有故障的柱面、在每个区中预留出一组柱面作为备用。所以格式化容量要比最大容量小。

**3、磁盘操作**

磁盘用**读写头**来读写存储在磁性表面的位。每个表面都有一个读写头，任何时候所有的**读写头都位于同一个柱面上**。

读写头位于**传动壁**的末端，读写头的速度约为 80km/h，距磁盘表面约 1um，因此**磁盘是很脆弱的，开机时不要挪动主机更不要拍主机**。

磁盘读写数据时**以扇区为单位**，即一次读写一个扇区大小的块。

![image-20220508165434630](https://s2.loli.net/2022/05/08/8tpbHi7MkqwWsor.png)

对扇区的访问时间包括三部分：

**寻道时间：**为了读取目标扇区的内容，传动臂首先要将读写头定位到包含目标扇区的磁道上。

现代驱动器的平均寻道时间为 3~9 ms，最大为 20 ms。（机械原理）

这个时间除**跨越n条磁道的时间**外，还包括**启动磁臂**的时间s，即
$$
Tseek=m*n+s上式中，**m是与磁盘驱动器速度有关的常数**，约为0.2ms，磁臂的启动时间s：约为2ms。
$$
**旋转时间：**读写头定位到期望的磁道后，要等待目标扇区的第一个位旋转到读写头下。

1. 旋转时间依赖于磁盘的旋转速度和读写头到达目标磁道时的位置。
2. 最大旋转时间是旋转速度的倒数，平均旋转时间是最大旋转时间的一半。

盘片以**固定速率**旋转，通常为 5400~15000，单位是**转每分钟 (RPM)**。

设磁盘的旋转速度为RPM，则最大旋转时间(以秒为单位)，为：
$$
Tmr=(1/RPM)*(60secs/1min)
$$
平均旋转延迟，Tavg旋转时间，只是Tmax旋转时间的一半。一般的旋转时间是指的平均旋转时间：
$$
Tar=(1/RPM)*(60secs/1min)/2
$$
可以简化为王道书上的，其中r为磁盘每秒的转数
$$
Tr=1/2r
$$
对于硬盘，典型的旋转速度为5400 转/分，相当于一周11.1ms， 则Tr为5.55ms;

Tr=(1/5400)*60/2=11.1ms/2=5.55ms

对于软盘，其旋转速度为300~600转/分，则T为50~100ms。

**传送时间：**平均传送时间是读写头读写完整个扇区的时间。一个扇区的传输时间取决于转速和每个轨道扇区的数量。

![image-20220508190843012](https://s2.loli.net/2022/05/08/NkS3qdZ5zPYQ4RE.png)

王道书上：

传送时间取决于磁盘的旋转速度和每次读写的字节数b。N为一个磁道上的字节数

![image-20220508192217270](https://s2.loli.net/2022/05/08/vj7mHawArVfchyi.png)



旋转时间一般和寻道时间差不多，而传送时间相对可以忽略不计，因此**从磁盘读取一个扇区的时间约为 10 ms。**

例题：

![image-20220508192719856](https://s2.loli.net/2022/05/08/yFlVsUTgQPD2Irj.png)

例题：

![image-20220508200538620](https://s2.loli.net/2022/05/08/UD6XAMmZV8LGjhS.png)

**4、逻辑磁盘块**

现代磁盘呈现为一个逻辑块的序列，每个逻辑块是扇区大小的整数倍，最简单的情况下，逻辑块的大小为一个扇区，即 512 字节。块从0开始编号，块号是一系列增长的数字。

磁盘控制器保持物理扇区和逻辑块之间的映射。当操作系统读写磁盘时，发送一个**逻辑块号**到**磁盘控制器**，控制器上的固件将逻辑块号翻译为一个（盘面、磁道、扇区）的三元组。

**5、连接 I/O 设备**

系统总线与内存总线都是与 CPU 相关的，而 IO 总线与 CPU 无关。

Intel 的**外部设备互连总线（PCI）**就是一种 IO 总线（广播总线）。

IO 总线速度相比于系统总线和内存总线慢，但是可以容纳种类繁多的第三方 IO 设备。

连接到 IO 总线的**三种设备**：

1. **通用串行总线（USB）**：USB 总线是一个广泛使用的**标准**，连接各种 IO 设备，包括键盘、鼠标等。
2. **显卡/显示适配器：**负责代表 CPU 在显示器上画像素。
3. **主机总线适配器：**连接磁盘。常总的磁盘接口是 **SCSI 和 SATA**。其中 SCSI 比 SATA 更快也更贵。

​    ![0](https://note.youdao.com/yws/public/resource/1cbaebb119458e1d6043099a42e3db7c/xmlnote/546D3DB5DA8C4F179C441CC7B05098E0/40195)

**6、访问磁盘**

CPU 使用**内存映射 IO 技术**来向 IO 设备发射命令。在使用内存映射 IO 的系统中，地址空间中有一块地址是专为与 IO 设备通信保留的，每个这样的地址称为一个 IO 端口。当一个设备连接到总线时，它与一个或多个端口相关联。

假设磁盘控制器映射到端口 0xa0，**读一个磁盘扇区的步骤如下：**

1. CPU 依次发送命令字、逻辑块号、目的内存地址到 0xa0，发起一个磁盘读。因为磁盘读的时间很长，所以此后 CPU 会转去执行其他工作。

   ![image-20220508201953072](https://s2.loli.net/2022/05/08/qbPfVQ2psKJ7zOC.png)

2. 磁盘收到读命令后，将逻辑块号翻译成一个扇区地址，读取该扇区的内容，并将内容直接传送到主存，不需要经过 CPU (这称为**直接内存访问(DMA)**)。

   ![image-20220508202049560](https://s2.loli.net/2022/05/08/GS8OnEZtLApFMJl.png)

3. DMA 传送完成后，即磁盘扇区的内容安全地存储在主存中后，磁盘控制器给 CPU 发送一个中断信号来通知 CPU。

   ![image-20220508202109446](https://s2.loli.net/2022/05/08/QWSiabfqCghjy7H.png)



### **6.1.3 固态硬盘**

**固态硬盘 (SSD)** 是一种基于闪存的存储技术。

一个固态硬盘中封装了一个**闪存翻译层**和多个闪存芯片。闪存翻译层是一个硬件/固件设备，功能类似磁盘控制器，将对逻辑块的请求翻译成对底层物理设备的访问。

一个闪存由 B 个块的序列组成，每个块由 P 页组成，页的大小为 512byte~4kb。数据以页为单位进行读写。

[![enter description here](https://data2.liuin.cn/story-writer/2018_1_28_1517110224118.jpg)](https://data2.liuin.cn/story-writer/2018_1_28_1517110224118.jpg)

对于 SSD 来说，**读比写快**。因为只有在一页所属的块整个被擦除后，才能写这一页。重复写十万次后，块就会磨损，因此固态硬盘寿命较低。

![image-20220508212736990](https://s2.loli.net/2022/05/08/V824UzwPA7fGdyZ.png)

**随机写 SSD 很慢的两个原因：**

1. 擦除块需要相对较长的时间。
2. 如果写操作试图修改一个已经有数据的页，那么这个块中所有带有用数据的页都必须复制到一个新的块，然后才能向该页写数据。

**SSD 相比于旋转磁盘的优点：**由半导体存储器构成，没有移动部件，所以更结实，随机访问也更快，能耗更低。

**缺点**：更容易磨损，不过现在的 SSD 已经可以用很多年了。

基于闪存（flash memory）的存储技术



### 6.1.4 存储技术趋势

**性能上：**SRAM > DRAM > SSD > 旋转磁盘

**发展速度上**：增加密度(降低成本) > 降低访问时间

DRAM 和 磁盘的性能滞后于 CPU 的性能提升速度，两者之间的差距越来越大。

![image-20220508213652205](https://s2.loli.net/2022/05/08/Ht4iFWQM5PBlERL.png)

## 6.2 局部性

**局部性**

实际上弥补CPU和内存之间差距的关键，是程序的局部性。

局部性是程序的一个基本属性。具有良好局部性的程序倾向于**重复地访问相同的数据 (时间局部性)**，或倾向于**访问邻近的数据 (空间局部性)**，因此运行更快。

**局部性有两种形式**：时间局部性和空间局部性。

现代计算机系统的各个层次，从硬件到操作系统到应用程序都利用了局部性。

### **6.2.1 对程序数据引用的局部性**

​                for(int i=0; i<N; ++i)    sum += v[i];              

上例中，sum 具有好的时间局部性，向量 v 具有好的空间局部性。

这里对向量 v 中元素的访问是顺序访问的，称为**步长为 1 的引用模式**。在空间局部性上，步长为 1 的引用模式是最好的。

### **6.2.2 取指令的局部性**

程序指令存放在内存中，CPU 需要读这些指令，因此取指令也有局部性。比如 for 循环中的指令具有好的时间局部性和空间局部性。

### **6.2.3 局部性小结**

**评价局部性的简单原则：**

1. 重复引用相同变量的程序有好的时间局部性。
2. 对于步长为 k 的引用模式的程序，k 越小，空间局部性越好。
3. 对于取指令来说，循环有好的时间和空间局部性。循环体越小，循环迭代次数越多，局部性越好。



## 6.3 存储器层次结构

![https://note.youdao.com/yws/public/resource/1cbaebb119458e1d6043099a42e3db7c/xmlnote/50EB11D7A28F4BAA9E08302865BDE592/50927](https://note.youdao.com/yws/public/resource/1cbaebb119458e1d6043099a42e3db7c/xmlnote/50EB11D7A28F4BAA9E08302865BDE592/50927)

### 6.3.1 在存储器层次结构中的缓存

一般而言，高速缓存(cache)是一个小而快速的存储设备。使用高速缓存的过程称为缓存(caching)。

**存储器层次结构的中心思想**：对于每个 k，位于 k 层的更快更小的存储设备作为位于 k+1 层的更大更慢的存储设备的缓存。换句话说，层次结构中的每一次都缓存来自较低一层的数据对象。

**缓存的具体实现：**数据总是以块大小为传送单元(transfer unit)在第 k 层和第 k+1 层之间来回拷贝的。虽然在层次结构中任何一对相邻的层次之间块大小是固定的，但是其他的层次对之间可以用不同的块大小。

一般而言，层次结构较低的层(离 CPU 较远)的设备访问时间较长，因此为了补偿这些较长的访问时间，倾向于使用较大的块。

[![enter description here](https://data2.liuin.cn/story-writer/2018_1_28_1517110523087.jpg)](https://data2.liuin.cn/story-writer/2018_1_28_1517110523087.jpg)

**1、缓存命中**

当需要 k+1 层的某个数据对象 d 时，如果 d 恰好缓存在 k 层中，就称为缓存命中。

**2、缓存不命中**

缓存不命中时，第 k 层的缓存从 第 k+1 层缓存中取出包含 d 的块。

如果第 k 层缓存已经满了，需要根据替换策略选择一个块进行覆盖 (替换)，未满的话需要根据放置策略来选择一个块放置。

**3、缓存不命中的种类**

1. **冷不命中**：一个空的缓存称为**冷缓存**，冷缓存必然不命中，称为冷不命中。
2. **冲突不命中：**常用的放置策略是将 k+1 层的某个块限制放置在 k 层块的一个小的子集中。比如 k+1 层的块 1,5,9,13 映射到 k 层的块 0。这会带来冲突不命中。
3. **容量不命中**：当访问的工作集的大小超过缓存的大小时，会发生容量不命中。即缓存太小了，不能缓存整个工作集。

**4、缓存管理**

寄存器文件的缓存由编译器管理，L1,L2,L3 的缓存由内置在缓存中的硬件逻辑管理，DRAM 主存作为缓存由操作系统和 CPU 上的地址翻译硬件共同管理。

### 6.3.2 存储器层次结构概念小结

存储器层次结构行之有效，因为较慢的设备比较快的设备更便宜，还因为程序偏向于展示局部性：

- 利用时间局部性，同一数据对象可能会被多次使用
- 利用空间局部性，块通常包含有多个数据对象

[![enter description here](https://data2.liuin.cn/story-writer/2018_1_28_1517110831456.jpg)](https://data2.liuin.cn/story-writer/2018_1_28_1517110831456.jpg)



## 6.4 高速缓存存储器

L1 高速缓存的访问速度约为 4 个时钟周期，L2 约 10 个周期，L3 约 50 个周期。

当 CPU 执行一条读内存字 w 的指令，它首先向 L1 高速缓存请求这个字，如果 L1 没有就向 L2，依此而下。

### 6.4.1 通用的高速缓存存储结构

假设一个计算机系统中的存储器地址有 m 位，形成 M =2^m 个不同的地址。m 个地址为划分为 **t 个标记位**，**s 个组索引位**，**b 个块偏移位**。

高速缓存被组织成 S=2^s 个**高速缓存组**，每个组包含 E 个**高速缓存行**，**每个行为一个数据块**，包含一个**有效位**，t=m-(b+s) 个**标记位**，和 B=2^b 字节的**数据块**。高速缓存的容量 = S * E * B。

**高速缓存可以通过简单地检查地址位来找到所请求的字。**

当 CPU 要从地址 A(由m个地址位组成) 处读一个字时：

1. A 中的 s 个组索引位告诉我们在哪个组中
2. A 中的 t 个标记位告诉我们在这个组中的哪一行：当且仅当这一行设置了有效位并且标记位与 A 中的标记位匹配时，才说明这一行包含这个字。
3. A 中的 b 个块偏移位告诉我们在 B 个字节的数据块中的字偏移。

![img](https://note.youdao.com/yws/public/resource/1cbaebb119458e1d6043099a42e3db7c/xmlnote/80E48F8D9F6B44EC827C5A890091D2B4/40197)

![image-20220517115624247](https://s2.loli.net/2022/05/17/mUPZ8qux5VJODks.png)

![image-20220517120310461](https://s2.loli.net/2022/05/17/B4KzO5S7sC8hNeg.png)

**理解**

使用高位做标记位，可以避免连续的块被映射到同一高速缓存组中。

**通过高速缓存从内存读字**

假设一个系统中只有 CPU、L1 高速缓存和主存。

当 CPU 执行一条从内存读字 w 的指令，如果 L1 有 w 的副本，就得到 L1 高速缓存命中；如果 L1 没有，就是缓存不命中。

当缓存不命中，L1 会向主存请求包含 w 的块(L1 中的块就是它的高速缓存行)的一个副本。当块从内存到达 L1，L1 将这个块存在它的一个高速缓存行里，然后从中抽取出字 w，并返回给 CPU。

高速缓存确定一个请求是否命中，然后抽取出被请求的字的过程分为三步：

1. **组选择**
2. **行匹配**
3. **字抽取**

**高速缓存有以下几类：**

1. **直接映射高速缓存**：每个组只有一行，即 E=1。
2. **组相联高速缓存**：每个组有多行，1
3. **全相联高速缓存**：只有一个组，E=C/B。

### 6.4.2 直接映射高速缓存

每个组只有一行（E=1）的高速缓存被称为直接映射高速缓存

**1、直接映射高速缓存中的组选择**

​    ![0](https://note.youdao.com/yws/public/resource/1cbaebb119458e1d6043099a42e3db7c/xmlnote/A23B622FF5BB48D792FC46C9394D3C36/40198)

从 w 的 m 位地址中抽取出 s 个组索引位，并据此选择相应的高速缓存组。

**2、直接映射高速缓存中的行匹配**

因为直接映射高速缓存每个组只有一行，只要这一行设置了有效位且标记位相匹配，就说明想要的字的副本确实存储在这一行中。

**3、直接映射高速缓存中的字抽取**

从 w 的地址中抽取出 b 个块偏移位，块偏移位提供了所需的字的第一个字节的偏移。

**4、直接映射高速缓存不命中时的行替换**

缓存不命中时需要从下一层取出被请求的块，然后将其存储在组索引位指示的组中的高速缓存行中。

因为直接映射高速缓存每个组只有一行，所以替换策略很简单：用新取出的行替换当前行。

**5、运行中的直接映射高速缓存**

标记位和索引位连接起来标识了整个内存中的所有块，而高速缓存中的高速缓存组（块）是少于内存中的块数的。因此位于不同标记位，相同组索引位的块会映射到高速缓存中的同一个高速缓存组。

在一个高速缓存组中存储了哪个块，可以由标记位唯一地标识。

理解：对于主存中的整个地址空间，根据标记位不同将其分为了若干个部分，每个部分可以单独且完整地映射到高速缓存中，且刚好占满整个直接映射高速缓存。

**6、直接映射高速缓存中的冲突不命中**

冲突不命中在直接映射高速缓存中很常见。因为每个组只有一行，不同标记位的块会映射到同一行，发生冲突不命中。

### 6.4.3 组相联高速缓存

直接映射高速缓存中冲突不命中造成的问题是源于每一个组只有一行，组相联高速缓存（set associative cache）放松了这条限制，所以每个组都保存了有多于一行的高速缓存

**1、组相联高速缓存中的组选择**

与直接映射高速缓存一样，组索引位标识组。

**2、组相联高速缓存中的行匹配**

组相联高速缓存中的行匹配更复杂，因为要**检查多个行的标记位和有效位**，以确定其中是否有所请求的字。

注意：组中的任意一行都可能包含映射到这个组的内存块，因此**必须搜索组中的每一行**，寻找一个有效且标记位相匹配的行。

**3、组相联高速缓存中的字抽取**

与直接映射高速缓存一样，块偏移位标识所请求的字的第一个字节。

**4、组相联高速缓存中不命中时的行替换**

**几种替换策略**

1. **随机替换策略：**随机选择要替换的行
2. **最不常使用策略：**替换在过去某个时间窗口内引用次数最少的一行。
3. **最近最少使用策略：**替换最后一次访问时间最久远的那一行。

因为存储器层次结构中越靠下，不命中开销越大，好的替换策略越重要。



[![enter description here](https://data2.liuin.cn/story-writer/2018_1_28_1517111477325.jpg)](https://data2.liuin.cn/story-writer/2018_1_28_1517111477325.jpg)

### 6.4.4 全相联高速缓存

全相联高速缓存由一个包含所有高速缓存行 (E=C/B) 的组组成。

因为高速缓存电路必须并行地搜索不同组已找到相匹配的标记，所以全相联高速缓存只适合做小的高速缓存。

DRAM 主存采用了全相联高速缓存，但是因为它采用了虚拟内存系统，所以在进行类似行匹配的页查找时不需要对一个个页进行遍历。

**1、全相联高速缓存中的组选择**

全相联高速缓存中只有一个组，所以地址中没有组索引位，只有标记位和块偏移位。

**2、全相联高速缓存中的行匹配和字抽取**

与组相联高速缓存一样。与组相联高速缓存的区别在于规模大小

[![enter description here](https://data2.liuin.cn/story-writer/2018_1_28_1517111577074.jpg)](https://data2.liuin.cn/story-writer/2018_1_28_1517111577074.jpg)

[![enter description here](https://data2.liuin.cn/story-writer/2018_1_28_1517111592957.jpg)](https://data2.liuin.cn/story-writer/2018_1_28_1517111592957.jpg)

[![enter description here](https://data2.liuin.cn/story-writer/2018_1_28_1517111605869.jpg)](https://data2.liuin.cn/story-writer/2018_1_28_1517111605869.jpg)

### 6.4.5 有关写的问题

写相比读要复杂一些。

写命中（写一个已经缓存了的字 w）的情况下，高速缓存更新了本层的 w 的副本后，如何处理低一层的副本有两种方法：

1. **直写**：立即将 w 的高速缓存块写回到低一层中。

2. 1. 优点：简单
   2. 缺点：每次写都会占据总线流量

3. **写回**：尽可能地推迟更新，只有当替换算法要驱逐这个更新过的块时，才把它写到低一层中。

4. 1. **优点：利用了局部性，可以显著地减少总线流量。**
   2. 缺点：增加了复杂性。必须为每个高速缓存行维护一个额外的修改位，表明此行是否被修改过。

**写不命中**情况下的两种方法：

1. **写分配**：加载相应的低一层的块到本层中，然后更新这个高速缓存块。

2. 1. 优点：利用写的空间局部性
   2. 缺点：每次不命中都会导致一个块从低一层传送到高速缓存

3. **非写分配**：避开高速缓存，直接把这个字写到低一层中

直写一般与非写分配搭配，两者都更适用于存储器层次结构中的较高层。

**写回一般与写分配搭配，两者都更适用于存储器层次结构中的较低层，因为较低层的传送时间太长。**

因为硬件上复杂电路的实现越来越容易，所以现在使用写回和写分配越来越多。

### 6.4.6 指令高速缓存和统一高速缓存

**三种高速缓存：**

1. **i-cache：**只保存指令的高速缓存。i-cache 通常是只读的，因此比较简单。
2. **d-cache：**只保存程序数据的高速缓存。
3. **统一的高速缓存：**既保存指令又保存程序数据。

现代处理器一般包括独立的 i-cache 和 d-cache，其中两个原因如下：

1. 使用两个独立的高速缓存，CPU 可以同时读一个指令字和一个数据字。
2. 可以确保数据访问不会与指令访问形成冲突不命中（不过可能会使容量不命中增加）。

**Core i7 的高速缓存层次结构及其特性**

​    ![0](https://note.youdao.com/yws/public/resource/1cbaebb119458e1d6043099a42e3db7c/xmlnote/A8844E9477484BE48E840DC8A34E150D/40180)

​    ![0](https://note.youdao.com/yws/public/resource/1cbaebb119458e1d6043099a42e3db7c/xmlnote/A3CFF9BC545A495995BC1EDE5AB4E38F/40194)

### 6.4.7 高速缓存参数的性能影响

1. **高速缓存的性能指标**

   1. **命中率：**命中的内存引用比率。
   2. **命中时间**：从高速缓存传送一个字到 CPU 的时间，包括组选择、行确认和字抽取的实践。
   3. **不命中处罚：**不命中产生的额外时间消耗。

   **几个影响因素**

   1. 高速缓存大小：较大的高速缓存可以提高命中率，但是会运行得更慢，即增加命中时间。
   2. 块大小：较大的块更能利用空间局部性以提高命中率。但是对于给定的总容量，块越大高速缓存行就越少，不利用利用时间局部性。较大的块因为传送时间更长，所以也会增加不命中处罚。现代处理系统的高速缓存块一般为 64 字节。
   3. 相联度：参数E的选择的影响（每个组中高速缓存行数）。E越高优点是：降低了高速缓存由于冲突不命中出现抖动的可能性。缺点：实现起来昂贵；增加命中时间；增加不命中处罚。
   4. 写策略：高速缓存越往下层，越可能使用写会而不是直写策略。

## 6.5 编写高速缓存友好的代码

1. 让最常见的情况运行得快
2. 在每个循环内部使缓存不命中数量小

## 6.6 综合：高速缓存对程序性能的影响

存储器山（memory mountain）
[![enter description here](https://data2.liuin.cn/story-writer/2018_1_28_1517112396218.jpg)](https://data2.liuin.cn/story-writer/2018_1_28_1517112396218.jpg)

## 6.7 小结

程序员可以通过编写有良好空间和时间局部性的程序来显著地改进程序的运行时间。利用基于 SRAM 的高速缓存存储器特别重要。

# 9 虚拟内存 

## 前言：

**ELF文件**

对于每个程序，其在经历预处理、编译、汇编之后，都要经过链接器将其链接成一个单一的可执行文件。在现在Unix和x86-64 Linux系统上，其使用的可执行格式为ELF，如下：

![img](https://s2.loli.net/2022/05/19/PjVzpEMadt4K29m.jpg)

可以看到ELF涵盖了程序中的各种信息，加载器就是通过读取ELF文件中的数据和代码，将其从磁盘复制到内存中，生成相应的进程并跳转到第一条指令或入口点来运行该程序。

**进程**

进程地址空间如下图所示：

![img](https://img-blog.csdnimg.cn/20200330182652416.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hwc3ljaGU=,size_16,color_FFFFFF,t_70)

 

可以看到，只读代码和数据对应于elf文件的（.init,.text,.rodata），读写段对应于elf文件的（.data,.bss）。

问题来了，如果我们有很多个程序要运行，所需内存已经超过了我们物理内存的容量，此时该怎么处理呢？

其实，当程序运行时，如果内存空间足够大，操作系统会按分页机制，将程序调入内存中。否则，操作系统会分批将程序的部分内容调入内存，再通过磁盘上的虚拟内存来实现内存置换，达到按需加载的目的。

到这里对虚拟内存有一定的概念了，似乎其作用就是“虚拟地扩充我们的内存”。

**虚拟内存**

为了更加有效地管理内存，操作系统对**主存提出了一种抽象的概念**：**虚拟内存**。其通过**硬件+软件**的支持，为进程提供了更大的、一致的和私有的地址空间。虚拟内存主要提供一下三个能力：

　　1）它将主存看成是一个存储在磁盘上的地址空间的**高速缓存**，在主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据，通过这种方式，它高效地使用了主存。

　　2）它为每个进程提供了**一致的地址空间**，从而简化了存储器管理；

　　3）保护了每个进程的地址空间不被其他进程破坏；

 

虚拟存储器是计算机系统最重要的概念之一。它的成功在于它是沉默地、自动地工作着，不需要应用程序员的任何干涉。

既然虚拟存储器在幕后工作得如此之好，为什么程序员还要理解它，原因有以下几个：

1）**虚拟存储器是中心的**。

　　虚拟存储器遍及计算机系统的所有层面，理解虚拟存储器将帮助更好地理解系统通常是如何工作的。

2）**虚拟存储器是强大的**。

　　虚拟存储器给予应用程序强大的能力。可以创建和销毁存储器的片（chunk），将存储器映射到磁盘文件的某个部分，以及与其他进程共享存储器。

3）**虚拟存储器是危险的**。

　　每次应用程序引用一个变量、间接引用一个指针，或者调用一个诸如malloc这样的动态分配程序时，它就会和虚拟存储器发生交互。如果虚拟存储器使用不当，应用将遇到复杂危险的与存储器有关的错误。例如，一个带有错误指针的程序可以立即崩溃于“段错误”或者“保护错误”，它可能在崩溃之前还默默地运行了几个小时，或者是最令人惊慌地，运行完成却产生不正确的结果。

 

这篇文章主要讲述**两方面**：

1）虚拟存储器是如何工作的；

2）应用程序如何使用和管理虚拟存储器；

## 9.1 物理和虚拟寻址

计算机系统的主存被组织成一个由M个连续的字节大小的单元组成的数组。

每字节都有唯一的**物理地址（Physical Address）PA**。

第一个字节的地址为0，接下来的字节地址为1，以此类推。

 

CPU访问存储器最自然的方式就是使用物理地址。这种寻址方式被称为**物理寻址**。

当CPU执行一条加载指令时，它会生成一个有效的物理地址，通过存储器总线，把它传递给主存。

主存取出从物理地址4处开始的4字节的字，并 将它返回给CPU，CPU会将它存放在一个寄存器中。

 ![img](https://s2.loli.net/2022/05/18/vPlUGXzONZwj8aY.png)

 

现代处理器使用的是一种称为**虚拟寻址**的寻址方式。 

使用虚拟寻址时，CPU通过生成一个虚拟地址来访问主存，这个虚拟地址在被送到存储器之前先转换成适当的物理地址。

将一个虚拟地址转换成物理地址的任务叫做**地址翻译**。CPU芯片上叫做**MMU(Memory Management Unit)存储器管理单元**的专用硬件会进行这个任务。

地址翻译的任务需要硬件和操作系统紧密配合，MMU会利用放在主存上的查询表来动态翻译虚拟地址，该表的内容由操作系统来管理。

![img](https://img2018.cnblogs.com/blog/1295079/201904/1295079-20190411083358049-574228926.png)

## 9.2 地址空间

**地址空间**是一个非负整数地址的有序集合：{0,1,2,...}

如果地址空间中的整数是连续的，那么我们说它是**线性地址空间**。

为了简化讨论，我们总是假设地址空间是线性地址空间。

在带虚拟存储器的系统中，CPU从一个有N=2^n 个地址的地址空间中生成虚拟地址，这个地址空间称为**虚拟地址空间**。 

一个地址空间的大小是由表示最大地址所需要的位数来描述的。

例如，一个包含N=2^n个地址的虚拟地址空间叫做一个n位地址空间。

现代系统典型地支持32位或者64位**虚拟地址空间**。

 

一个系统还有**物理地址空间**，它与系统中物理存储器的M个字节相对应：{0,1,2，...，M-1}

M不要求是2的幂，但为了简化讨论，一般假设M=2^m。物理地址空间对应于系统中实际拥有DRAM容量。



地址空间的概念非常重要。

它清楚地区分了数据对象（字节）和它们的属性（地址）。

主存中的每个字节都有一个选自虚拟地址空间的虚拟地址和一个选自物理地址空间的物理地址。

允许每个数据对象有多个独立的地址，其中每一个地址都选自一个不同的地址空间。这就是虚拟存储器的基本思想

## 9.3 虚拟内存作为缓存的工具

概念上而言，虚拟内存(VM)被组织为一个由存放在**磁盘上**的 N 个连续的字节大小的单元组成的数组。

每字节都有一个唯一的虚拟地址，这个唯一的虚拟地址是作为到数组的索引的。

VM 系统通过将虚拟存储器分割为**虚拟页(Virtual Page, VP)**的大小固定的块来处理这个问题。每个虚拟页的大小为 P=2^p 字节。

类似地，物理存储器被分割为物理页(Physical Page, PP)，大小也为 P 字节(**物理页也称为页帧(page frame))。**

在任意时刻，虚拟页面的集合部分都分为三个不相交的子集：

- **未分配的**：VM 系统还未分配(或者创建)的页。未分配的块没有任何数据和它们相关联，因此也就不占用任何磁盘空间。
- **缓存的：**当前缓存在物理存储器中的已分配页。
- **未缓存的：**没有缓存在物理存储器中的已分配页。

![image-20220518201115374](https://s2.loli.net/2022/05/18/7lbm3FKQOaoRYuU.png)

### 9.3.1 DRAM高速缓存的组织结构

在存储层次结构中，DRAM缓存的位置对于他的组织结构有很大的影响。DRAM 缓存的组织结构完全是由巨大的不命中开销驱动的。

因为大的不命中处罚和访问第一字节的开销，虚拟页往往很大，典型地是4KB-2MB。由于大的不命中处罚，DRAM 缓存是全相连的，也就是说，任何虚拟页都可以放置在任何的物理页中。

不命中时的替换策略也很重要，因为替换错了虚拟页的处罚也非常高。因此，与硬件对 SRAM 缓存相比，操作系统对 DRAM 缓存使用了更复杂精密的替换算法。最后，因为对磁盘的访问时间很长，DRAM 缓存总是使用写回(write back)，而不是直写。

**术语SRAM缓存**来表示位于CPU和主存之间的L1、L2、L3高速缓存；高速缓存

**术语DRAM缓存**来表示虚拟存储器系统的缓存，它在主存中缓存虚拟页；主存缓存

![img](https://img2018.cnblogs.com/blog/1295079/201904/1295079-20190412095312734-418215725.png)

SRAM比DRAM快大约10倍，DRAM比磁盘快大约100000倍；

DRAM不命中，要由本地磁盘服务；

SRAM不命中，要由DRAM服务；

### 9.3.2 页表

页表将虚拟页映射到物理页；

每次地址翻译硬件将虚拟地址转换为物理地址时都会读取页表。

操作系统负责维护页表的内容，以及在磁盘与DRAM之间来回传送页。

通过页表，虚拟存储器系统可以判定一个虚拟页是否存放在DRAM中的某个地方。如果是，系统还必须确定这个虚拟页放在哪个物理页中。

如果不命中，系统必须判断这个虚拟页存放在磁盘的哪个位置。

在物理存储中选择一个牺牲页，并将**虚拟页从磁盘拷贝到DRAM中**，替换这个**牺牲页**。

这些功能是由许多软硬件联合提供的，包括操作系统软件、MMU（存储器管理单元）中的地址翻译硬件和一个存放在物理存储器中的叫做页表的数据结构。

页表是页表条目(Page Table Entry, PTE)的一个数组；

每个PTE是由一个有效位和一个n位地址字段构成的。

有效位表明当前虚拟页是否缓存在DRAM中。

地址字段表明DRAM中相应的物理页起始位置。

如果没有设置有效位，空地址表示虚拟页还没有被分配；否则这个地址指向虚拟页在磁盘上的起始位置。**（虚拟页映射到磁盘中不叫缓存）**。

![img](https://1087580735-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-MHt_spaxGgCbp2POnfq%2F-MIYN88g0ZggqR-FZ1H0%2F-MIYNXywdCmTKdv_JdK0%2F09-04%20%E9%A1%B5%E8%A1%A8.png?alt=media&token=6b63482e-5ae9-4369-b3f7-5e97c1c4dcc1)

​																			图 9-4 页表

### 9.3.3 页命中

![image-20220519211508538](https://s2.loli.net/2022/05/19/IAbT4VMv3skpPEc.png)

图 9-5 VM 页命中。对 VP 2 中一个字的引用就会命中

### 9.3.4 缺页

在虚拟内存的习惯说法中，DRAM 缓存不命中称为**缺页（page fault）**。图 9-6 展示了在缺页之前我们的示例页表的状态。CPU 引用了 VP 3 中的一个字，VP 3 并未缓存在 DRAM 中。地址翻译硬件从内存中读取 PTE 3，从有效位推断出 VP 3 未被缓存，并且触发一个缺页异常。缺页异常调用内核中的缺页异常处理程序，该程序会选择一个牺牲页，在此例中就是存放在 PP 3 中的 VP 4。如果 VP 4 已经被修改了，那么内核就会将它复制回磁盘。无论哪种情况，内核都会修改 VP 4 的页表条目，反映出 VP 4 不再缓存在主存中这一事实。

![img](https://1087580735-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-MHt_spaxGgCbp2POnfq%2F-MIYN88g0ZggqR-FZ1H0%2F-MIYO-fZ9JvakilBQ-ga%2F09-06%20VM%E7%BC%BA%E9%A1%B5%EF%BC%88%E4%B9%8B%E5%89%8D%EF%BC%89.png?alt=media&token=d01a27fe-0482-42da-8dae-b3dcac085a03)

​				图 9-6 VM 缺页（之前）。对 VP3 中的字的引用会不命中，从而触发了缺页

接下来，内核从磁盘复制 VP 3 到内存中的 PP 3，更新 PTE 3，随后返回。当异常处理程序返回时，它会重新启动导致缺页的指令，该指令会把导致缺页的虚拟地址重发送到地址翻译硬件。但是现在，VP 3 已经缓存在主存中了，那么页命中也能由地址翻译硬件正常处理了。图 9-7 展示了在缺页之后我们的示例页表的状态。

![img](https://1087580735-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-MHt_spaxGgCbp2POnfq%2F-MIYN88g0ZggqR-FZ1H0%2F-MIYOEtRCEpjF2HpuEcB%2F09-07%20VM%E7%BC%BA%E9%A1%B5%EF%BC%88%E4%B9%8B%E5%90%8E%EF%BC%89.png?alt=media&token=c6439fdf-2c7f-45b3-a527-c426630e968d)

> 图 9-7 VM 缺页（之后）。缺页处理程序选择 VP 4 作为牺牲页，并从磁盘上用 VP 3 的副本取代它。在缺页处理程序重新启动导致缺页的指令之后，该指令将从内存中正常地读取字，而不会再产生异常

虚拟内存是在 20 世纪 60 年代早期发明的，远在 CPU - 内存之间差距的加大引发产生 SRAM 缓存之前。因此，虚拟内存系统使用了和 SRAM 缓存不同的术语，即使它们的许多概念是相似的。在虚拟内存的习惯说法中，块被称为页。在磁盘和内存之间传送页的活动叫做**交换**（swapping）或者**页面调度**（paging）。页从磁盘换入（或者页面调入）DRAM 和从 DRAM 换出（或者页面调出）磁盘。一直等待，直到最后时刻，也就是当有不命中发生时，才换入页面的这种策略称为**按需页面调度**（demand paging）。也可以采用其他的方法，例如尝试着预测不命中，在页面实际被引用之前就换入页面。然而，所有现代系统都使用的是按需页面调度的方式。

### 9.3.5 分配页面

图 9-8 展示了当操作系统分配一个新的虚拟内存页时对我们示例页表的影响，例如，调用 malloc 的结果。在这个示例中，VP5 的分配过程是在磁盘上创建空间并更新 PTE 5，使它指向磁盘上这个新创建的页面。

![img](https://1087580735-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-MHt_spaxGgCbp2POnfq%2F-MIYN88g0ZggqR-FZ1H0%2F-MIYOZxZ6DSdgSSqmmOa%2F09-08%20%E5%88%86%E9%85%8D%E4%B8%80%E4%B8%AA%E6%96%B0%E7%9A%84%E8%99%9A%E6%8B%9F%E9%A1%B5%E9%9D%A2.png?alt=media&token=e1a7fd72-7ba3-4285-9a07-7e2e784de70d)

> 图 9-8 分配一个新的虚拟页面。内核在磁盘上分配 VP 5，并且将 PTE 5 指向这个新的位置

### 9.3.6 局部性再次搭救

尽管在整个运行过程中程序引用的不同页面的总数可能超出物理存储器总的大小，但是局部性原则保证了在任意时刻，程序往往在一个较小的活动页面(active page)集合上工作，这个集合叫做**工作集**(working set)或者**常驻集**(resident set)。

如果工作集的大小超出了物理存储器的大小，那么程序将产生一种不幸的状态，叫做**颠簸**（thrashing），这时页面将不断的换进换出。

## 9.4 虚拟内存作为存储管理的工具

OS为每个进程提供一个独立的页表，就是一个独立的虚拟地址空间。多个虚拟页面可以映射到同一个共享物理页面上。

![img](https://1087580735-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-MHt_spaxGgCbp2POnfq%2F-MIYOtHdQnyLwQfp2XkW%2F-MIYOvrxzEpUmciIUVl4%2F09-09%20VM%E5%A6%82%E4%BD%95%E4%B8%BA%E8%BF%9B%E7%A8%8B%E6%8F%90%E4%BE%9B%E7%8B%AC%E7%AB%8B%E7%9A%84%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4.png?alt=media&token=f5089792-afbc-421e-a258-874d72015cf5)

> 图 9-9 VM 如何为进程提供独立的地址空间。操作系统为系统中的每个进程都维护一个独立的页表

VM简化了链接和加载、代码和数据共享，以及应用程序的存储器分配。

**简化链接：**

独立的地址空间允许每个进程为它的**存储器映像**使用相同的格式，而不需要管 代码和数据 存放在物理存储器的何处。

　　这样大大简化了链接器的设计和实现，允许链接器生成全链接的可执行文件，这些可执行文件是独立于物理存储器中代码和数据的最终位置。

链接器现在可以假设每个程序都加载到完全相同的位置，所以链接器能提前知道程序要加载到哪里。

**简化加载：**虚拟内存使得容易向内存中加载可执行文件和共享对象文件。

**简化共享：**

独立地址空间为OS提供了一个管理用户进程和操作系统自身之间共享的机制。一般而言，每个进程都有自己私有的代码、数据、堆以及栈区域，是不与其他进程共享的。当要共享时，操作系统将不同进程中的虚拟页映射到相同的物理页面，从而多个进程共享这部分的代码。

**简化内存分配：**虚拟内存向用户进程提供一个简单的分配额外内存的机制。当一个用户程序要求额外的堆空间时候，操作系统分配 k 个适当的连续的虚拟内存页面，并且将他们映射到物理内存的中的 k 个任意页面，操作系统没有必要分配 k 个连续的物理内存页面。

## 9.5 虚拟内存作为存储器保护的工具

虚拟地址空间的有些部分是只读的，比如代码段；有些部分只能由内核执行。在64位系统上，指针和地址也是64位的，但实际上，真正的虚拟地址空间是48位的，48位之后的高比特位全部为0或者全部为1，这是英特尔的规则，高位都是1的地址是为内核（内核代码，内核数据）保留的，高位都是0的地址是为用户代码保留的。

因此，可以在PTE中设置一些位，表明用户代码是否可以访问某些虚拟页面，或者他们是否必须由内核访问，这就是所谓的管理员模式。

你还可以设置一些位，表明该页面是否可以读、写、执行。通过向PTE添加位的简单技术，我们提供了这种自动的方式来保护虚拟地址空间的不同部分面授未经授权的访问。MMU在每次访问时检查这些位，如果进行非法操作，那么它就会抛出一个异常，由内核来处理。

![img](https://1087580735-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-MHt_spaxGgCbp2POnfq%2F-MIYP3HdIQvRb4dEdrDG%2F-MIYPHWr6e5XYLi85WkY%2F09-10%20%E7%94%A8%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E6%9D%A5%E6%8F%90%E4%BE%9B%E9%A1%B5%E9%9D%A2%E7%BA%A7%E7%9A%84%E5%86%85%E5%AD%98%E4%BF%9D%E6%8A%A4.png?alt=media&token=75eaf7b4-d821-42e0-945c-a21f18f73229)

## 9.6 地址翻译

地址翻译的基础知识：

> 基本参数

| 符号  | 描述                     |
| ----- | ------------------------ |
| N=2^n | 虚拟地址空间中的地址数量 |
| M=2^m | 物理地址空间中的地址数量 |
| P=2^p | 页的大小（字节）         |

> 虚拟地址（VA）的组成部分

| 符号 | 描述                   |
| ---- | ---------------------- |
| VPO  | 虚拟页面偏移量（字节） |
| VPN  | 虚拟页号               |
| TLBI | TLB 索引               |
| TLBT | TLB 标记               |

> 物理地址（PA）的组成部分

| 符号 | 描述                   |
| ---- | ---------------------- |
| PPO  | 物理页面偏移量（字节） |
| PPN  | 物理页号               |
| CO   | 缓冲块内的字节偏移量   |
| CI   | 高速缓存索引           |
| CT   | 高速缓存标记           |

形式上来说，地址翻译是一个 N 元素的虚拟地址空间（VAS）中的元素和一个 M 元素的物理地址空间（PAS）中元素之间的映射，
$$
\rm MAP:VAS\rightarrow PAS \cup ∅
$$
这里：
$$
\rm MAP(A)= \begin{cases}A'&\text{如果虚拟地址}A\text{处的数据在PAS的物理地址}A'\text{处}\\∅ &\text{如果虚拟地址}A\text{处的数据不在物理内存中}\end{cases}
$$
下图展示了 **MMU** 如何利用**页表**来实现这种映射。

CPU 中的一个控制寄存器，**页表基址寄存器**（Page Table Base Register，PTBR）指向当前页表。

n 位的虚拟地址包含两个部分：

​			一个 p 位的**虚拟页面偏移**（Virtual Page Offset，VPO）

​			一个(n−p)位的**虚拟页号**（Virtual Page Number，VPN）

MMU 利用 VPN 来选择适当的 PTE。例如，VPN 0 选择 PTE 0，VPN 1 选择 PTE 1，以此类推。

将页表条目中**物理页号**（Physical Page Number，PPN）和虚拟地址中的 VP。串联起来，就得到相应的物理地址。

注意，因为物理和虚拟页面都是 P 字节的，所以**物理页面偏移**（Physical Page Offset，PPO）和 VPO 是相同的。

![img](https://1087580735-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-MHt_spaxGgCbp2POnfq%2F-MIYPLpzE9Ks_UYOpt28%2F-MIYQgjBI9_qvCIM8oAW%2F09-12 使用页表的地址翻译.png?alt=media&token=d7031a9b-e28f-4a61-885e-48d7a04f6f8a)

图 a 展示了当页面命中时，CPU 硬件执行的步骤：

​		**第 1 步：**处理器生成一个虚拟地址，并把它传送给 MMU。

​		**第 2 步：**MMU 生成 PTE 地址，并从高速缓存/主存请求得到它。

​		**第 3 步：**高速缓存/主存向 MMU 返回 PTE。

​		**第 4 步：**MMU 构造物理地址，并把它传送给高速缓存/主存。

​		**第 5 步：**高速缓存/主存返回所请求的数据字给处理器。

![img](https://1087580735-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-MHt_spaxGgCbp2POnfq%2F-MIYPLpzE9Ks_UYOpt28%2F-MIYR3rawYqAdHyw7EM6%2F09-13%20%E9%A1%B5%E9%9D%A2%E5%91%BD%E4%B8%AD%E5%92%8C%E7%BC%BA%E9%A1%B5%E7%9A%84%E6%93%8D%E4%BD%9C%E5%9B%BE.png?alt=media&token=1aad8dec-3521-4388-87f0-8a7bc48b5600)

> ​												图 9-13 页面命中（a）和缺页（b）的操作图
>
> （VA：虚拟地址。PTEA：页表条目地址。PTE：页表条目。PA：物理地址）

页面命中完全是由硬件来处理的，与之不同的是，**处理缺页**要求**硬件**和**操作系统内核协作**完成，如图 9-13 b 所示。

​		**第 1 步到第 3 步：**和图 9-13a 中的第 1 步到第 3 步相同。

​		**第 4 步：**PTE 中的有效位是零，所以 MMU 触发了一次异常，传递 CPU 中的控制到操作系统内核中的缺页异常处理程序。

​		**第 5 步：**缺页处理程序确定出物理内存中的牺牲页，如果这个页面已经被修改了，则把它换出到磁盘。

​		**第 6 步：**缺页处理程序页面调入新的页面，并更新内存中的 PTE。

​		**第 7 步：**缺页处理程序返回到原来的进程，再次执行导致缺页的指令。CPU 将引起缺页的虚拟地址重新发送给 MMU。因为虚拟页面		现在缓存在物理内存中，所以就会命中，在 MMU 执行了图 9-13 b 中的步骤之后，主存就会将所请求字返回给处理器。

**练习9.3**

给定一个 32 位的虚拟地址空间和一个 24 位的物理地址，对于下面的页面大小 P，确定 VPN、VPO、PPN 和 PPO 中的位数：

| P    | VPN 位数 | VPO位数 | PPN位数 | PPO位数 |
| ---- | -------- | ------- | ------- | ------- |
| 1KB  | 22       | 10      | 14      | 10      |
| 2KB  | 21       | 11      | 13      | 11      |
| 4KB  | 20       | 12      | 12      | 12      |
| 8KB  | 19       | 13      | 11      | 13      |

为了完全掌握地址翻译，你需要很好地理解这类问题。下面是如何解决第一个子问题：我们有 n=32 个虚拟地址位和 m=24 个物理地址位。页面大小是P=1 KB，这意味着对于 VPO 和 PPO，我们都需要 log2(1K)=10 位。（回想一下，VPO 和 PPO 是相同的。）剩下的地址位分别是 VPN 和 PPN。

### 9.6.1 结合高速缓存和虚拟内存

在任何既使用虚拟内存又使用 SRAM 高速缓存的系统中，都有应该使用虚拟地址还是使用物理地址来访问 SRAM 高速缓存的问题。尽管关于这个折中的详细讨论已经超出了我们的讨论范围，但是大多数系统是选择物理寻址的。使用物理寻址，多个进程同时在高速缓存中有存储块和共享来自相同虚拟页面的块成为很简单的事情。而且，高速缓存无需处理保护问题，因为访问权限的检査是地址翻译过程的一部分。

图 9-14 展示了一个物理寻址的高速缓存如何和虚拟内存结合起来。主要的思路是地址翻译发生在高速缓存查找之前。注意，页表条目可以缓存，就像其他的数据字一样。

![img](https://1087580735-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-MHt_spaxGgCbp2POnfq%2F-MIYPLpzE9Ks_UYOpt28%2F-MIYRUfwKpIOP07bMfU2%2F09-14 将VM与物理寻址的高速缓存结合起来.png?alt=media&token=edc18dde-68b7-4b1e-bade-e4edaebbdc97)

> 图 9-14 将 VM 与物理寻址的高速缓存结合起来
>
> （VA：虚拟地址。PTEA：页表条目地址。PTE：页表条目。PA：物理地址）

### 9.6.2 利用TLB加速地址翻译

正如我们看到的，每次 CPU 产生一个虚拟地址，MMU 就必须查阅一个 PTE，以便将虚拟地址翻译为物理地址。在最糟糕的情况下，这会要求从内存多取一次数据，代价是几十到几百个周期。如果 PTE 碰巧缓存在 L1 中，那么开销就下降到 1 个或 2 个周期。然而，许多系统都试图消除即使是这样的开销，它们在 MMU 中包括了一个关于 PTE 的小的缓存，称为**翻译后备缓冲器**（Translation Lookaside Buffer，TLB）。

TLB 是一个小的、虚拟寻址的缓存，其中每一行都保存着一个由单个 PTE 组成的块。TLB 通常有高度的相联度。如图 9-15 所示，用于组选择和行匹配的索引和标记字段是从虚拟地址中的虚拟页号中提取出来的。如果 TLB 有T=2t\small T = 2^tT=2t个组，那么 **TLB 索引**（TLBI）是由 VPN 的 t 个最低位组成的，而 **TLB 标记**（TLBT）是由 VPN 中剩余的位组成的。

![img](https://1087580735-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-MHt_spaxGgCbp2POnfq%2F-MIYPLpzE9Ks_UYOpt28%2F-MIYRksO9K4bUGw-eMN4%2F09-15%20%E8%99%9A%E6%8B%9F%E5%9C%B0%E5%9D%80%E4%B8%AD%E7%94%A8%E4%BB%A5%E8%AE%BF%E9%97%AETLB%E7%9A%84%E7%BB%84%E6%88%90%E9%83%A8%E5%88%86.png?alt=media&token=806ff687-79a9-47f0-949f-88a423a82aa5)

​																图 9-15 虚拟地址中用以访问 TLB 的组成部分

图 9-16 a 展示了当 TLB 命中时（通常情况）所包括的步骤。这里的关键点是，所有的地址翻译步骤都是在芯片上的 MMU 中执行的，因此非常快。

​		**第 1 步：**CPU 产生一个虚拟地址。

​		**第 2 步和第 3 步：**MMU 从 TLB 中取出相应的 PTE。

​		**第 4 步：**MMU 将这个虚拟地址翻译成一个物理地址，并且将它发送到高速缓存/主存。

​		**第 5 步：**高速缓存/主存将所请求的数据字返回给 CPU。

![img](https://1087580735-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-MHt_spaxGgCbp2POnfq%2F-MIYS43zB8XXLzT_XEe8%2F-MIYS7kg0k5_cXnng1cY%2F09-16%20TLB%E5%91%BD%E4%B8%AD%E5%92%8C%E4%B8%8D%E5%91%BD%E4%B8%AD%E7%9A%84%E6%93%8D%E4%BD%9C%E5%9B%BE.png?alt=media&token=c6c04fa9-df23-4793-b5bf-9268d165fdee)

​																图 9-16 TLB 命中和不命中的操作图

当 TLB 不命中时，MMU 必须从 L1 缓存中取出相应的 PTE，如图 9-16 b 所示。新取出的 PTE 存放在 TLB 中，可能会覆盖一个已经存在的条目。

### 9.6.3 多级页表

到目前为止，我们一直假设系统只用一个单独的页表来进行地址翻译。但是如果我们有一个 32 位的地址空间、4KB 的页面和一个 4 字节的 PTE，那么即使应用所引用的只是虚拟地址空间中很小的一部分，也总是需要一个 4MB 的页表驻留在内存中。对于地址空间为 64 位的系统来说，问题将变得更复杂。

用来压缩页表的常用方法是使用层次结构的页表。用一个具体的示例是最容易理解这个思想的。假设 32 位虚拟地址空间被分为 4KB 的页，而每个页表条目都是 4 字节。还假设在这一时刻，虚拟地址空间有如下形式：内存的前 2K 个页面分配给了代码和数据，接下来的 6K 个页面还未分配，再接下来的 1023 个页面也未分配，接下来的 1 个页面分配给了用户栈。图 9-17 展示了我们如何为这个虚拟地址空间构造一个两级的页表层次结构。

![img](https://1087580735-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-MHt_spaxGgCbp2POnfq%2F-MIYS43zB8XXLzT_XEe8%2F-MIYSQRmw1YVLcLCwahU%2F09-17%20%E4%B8%80%E4%B8%AA%E4%B8%A4%E7%BA%A7%E9%A1%B5%E8%A1%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84.png?alt=media&token=84ef1641-d162-4cc4-aa55-244e2e1d4ce2)

​								图 9-17 一个两级页表层次结构。注意地址是从上往下增加的

一级页表中的每个 PTE 负责映射虚拟地址空间中一个 4MB 的**片**（chunk），这里每一片都是由 1024 个连续的页面组成的。比如，PTE 0 映射第一片，PTE 1 映射接下来的一片，以此类推。假设地址空间是 4GB，1024 个 PTE 已经足够覆盖整个空间了。

如果片 i 中的每个页面都未被分配，那么一级 PTE i 就为空。例如，图 9-17 中，片 2 ~ 7 是未被分配的。然而，如果在片 i 中至少有一个页是分配了的，那么一级 PTE i 就指向一个二级页表的基址。例如，在图 9-17 中，片 0、1 和 8 的所有或者部分已被分配，所以它们的一级 PTE 就指向二级页表。

二级页表中的每个 PTE 都负责映射一个 4KB 的虚拟内存页面，就像我们查看只有一级的页表一样。注意，使用 4 字节的 PTE，每个一级和二级页表都是 4KB 字节，这刚好和一个页面的大小是一样的。

这种方法从两个方面减少了内存要求。第一，如果一级页表中的一个 PTE 是空的，那么相应的二级页表就根本不会存在。这代表着一种巨大的潜在节约，因为对于一个典型的程序，4GB 的虚拟地址空间的大部分都会是未分配的。第二，只有**一级页表才需要总是在主存**中；虚拟内存系统可以在**需要时创建、页面调入或调出二级页表**，这就减少了主存的压力；只有最经常使用的二级页表才需要缓存在主存中。

图 9-18 描述了使用 k 级页表层次结构的地址翻译。虚拟地址被划分成为 k 个 VPN 和 1 个 VPO。每个 VPN i 都是一个到第 i 级页表的索引，其中 1⩽i⩽k 。第 j 级页表中的每个 PTE，1⩽j⩽k−1，都指向第 j+1 级的某个页表的基址。第 k 级页表中的每个 PTE 包含某个物理页面的 PPN，或者一个磁盘块的地址。为了构造物理地址，在能够确定 PPN 之前，MMU 必须访问为个 PTE。对于只有一级的页表结构，PPO 和 VPO 是相同的。

![img](https://1087580735-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-MHt_spaxGgCbp2POnfq%2F-MIYSYnQTWPfIed9I-uw%2F-MIYStYJDcPefnKm8gje%2F09-18%20%E4%BD%BF%E7%94%A8k%E7%BA%A7%E9%A1%B5%E8%A1%A8%E7%9A%84%E5%9C%B0%E5%9D%80%E7%BF%BB%E8%AF%91.png?alt=media&token=fe830f54-7853-4f93-99c3-2c73faabada2)

​															图 9-18 使用 k 级页表的地址翻译

访问 k 个 PTE，第一眼看上去昂贵而不切实际。然而，这里 TLB 能够起作用，正是通过将不同层次上页表的 PTE 缓存起来。实际上，带多级页表的地址翻译并不比单级页表慢很多。

### 9.6.4 综合：端到端的地址翻译

在这一节里，我们通过一个具体的端到端的地址翻译示例，来综合一下我们刚学过的这些内容，这个示例运行在有一个 TLB 和 L1 d-cache 的小系统上。为了保证可管理性，我们做出如下假设：

- 内存是按字节寻址的。
- 内存访问是针对 1 字节的字的（不是 4 字节的字）。
- 虚拟地址是 14 位长的（n=14）。
- 物理地址是 12 位长的（m=12）。
- 页面大小是 64 字节（P=64）。
- TLB 是四路组相联的，总共有 16 个条目。
- L1 d-cache 是物理寻址、直接映射的，行大小为 4 字节，而总共有 16 个组。

图 9-19 展示了虚拟地址和物理地址的格式。因为每个页面是2^6=64字节，所以虚拟地址和物理地址的低 6 位分别作为 VPO 和 PPO。虚拟地址的高 8 位作为 VPN。物理地址的高 6 位作为 PPN。

![img](https://1087580735-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-MHt_spaxGgCbp2POnfq%2F-MIYSYnQTWPfIed9I-uw%2F-MIYT32mQ4T7mU4wzKOK%2F09-19%20%E5%B0%8F%E5%86%85%E5%AD%98%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%AF%BB%E5%9D%80.png?alt=media&token=16f4999a-d257-4144-be52-da0e8257b57d)

> 图 9-19 小内存系统的寻址。假设 14 位的虚拟地址（n=14），12 位的物理地址（m=12）和 64 字节的页面（P=64）

图 9-20 展示了小内存系统的一个快照，包括 TLB（图 9-20a）、页表的一部分（图 9-20b）和 L1 高速缓存（图 9-20c）。在 TLB 和高速缓存的图上面，我们还展示了访问这些设备时硬件是如何划分虚拟地址和物理地址的位的。

- **TLB。**TLB 是利用 VPN 的位进行虚拟寻址的。因为 TLB 有 4 个组，所以 VPN 的低 2 位就作为组索引（TLBI）。VPN 中剩下的高 6 位作为标记（TLBT），用来区别可能映射到同一个 TLB 组的不同的 VPN。
- **页表。**这个页表是一个单级设计，一共有2^8=256个页表条目（PTE）。然而，我们只对这些条目中的开头 16 个感兴趣。为了方便，我们用索引它的 VPN 来标识每个 PTE；但是要记住这些 VPN 并不是页表的一部分，也不储存在内存中。另外，注意每个无效 PTE 的 PPN 都用一个破折号来表示，以加强一个概念：无论刚好这里存储的是什么位值，都是没有任何意义的。
- **高速缓存。**直接映射的缓存是通过物理地址中的字段来寻址的。因为每个块都是 4 字节，所以物理地址的低 2 位作为块偏移（CO）。因为有 16 组，所以接下来的 4 位就用来表示组索引（CI）。剩下的 6 位作为标记（CT）。

![img](https://1087580735-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-MHt_spaxGgCbp2POnfq%2F-MIYSYnQTWPfIed9I-uw%2F-MIYUELkT0wCmuRQzryb%2F09-20a%20%E5%B0%8F%E5%86%85%E5%AD%98%E7%B3%BB%E7%BB%9F%E7%9A%84TLB.png?alt=media&token=879eba87-5f71-40af-86c0-d5d649837ae8)

> 图 9-20 (a) 小内存系统的 TLB：四组，16个条目，四路组相联

![img](https://1087580735-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-MHt_spaxGgCbp2POnfq%2F-MIYSYnQTWPfIed9I-uw%2F-MIYUNEqUexfOEuvU2Sf%2F09-20b%20%E5%B0%8F%E5%86%85%E5%AD%98%E7%B3%BB%E7%BB%9F%E7%9A%84%E9%A1%B5%E8%A1%A8.png?alt=media&token=19eb554b-26df-4d3d-a0d3-c8c854ed255c)

> 图 9-20 (b) 小内存系统的页表：只展示了前 16 个 PTE

![img](https://1087580735-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-MHt_spaxGgCbp2POnfq%2F-MIYSYnQTWPfIed9I-uw%2F-MIYUaf3gq7ChdGup4ZD%2F09-20c%20%E5%B0%8F%E5%86%85%E5%AD%98%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%BC%93%E5%AD%98.png?alt=media&token=33f736fd-b3aa-4500-b226-3244f9bb9b5d)

> 图 9-20 (c) 小内存系统的高速缓存：16 个组，4 字节的块，直接映射

> 图 9-20 小内存系统的 TLB、页表以及缓存。TLB、页表和缓存中所有的值都是十六进制表示的

给定了这种初始化设定，让我们来看看当 CPU 执行一条读地址 0x03d4 处字节的加载指令时会发生什么。（回想一下我们假定 CPU 读取 1 字节的字，而不是 4 字节的字。）为了开始这种手工的模拟，我们发现写下虚拟地址的各个位，标识出我们会需要的各种字段，并确定它们的十六进制值，是非常有帮助的。当硬件解码地址时，它也执行相似的任务。

![img](https://1087580735-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-MHt_spaxGgCbp2POnfq%2F-MIYUko9yvv6aGDarW78%2F-MIYV3odIJNAKHUFh1wH%2F09-20x.png?alt=media&token=619523d8-5fe8-46a7-8638-31e4f37c7a32)

开始时，MMU 从虚拟地址中抽取出 VPN（0x0F），并且检查 TLB，看它是否因为前面的某个内存引用缓存了 PTE 0x0F 的一个副本。TLB 从 VPN 中抽取出 TLB 索引（0x03）和 TLB 标记（0x3），组 0x3 的第二个条目中有效匹配，所以命中，然后将缓存的 PPN（0x0D）返回给 MMU。

如果 TLB 不命中，那么 MMU 就需要从主存中取出相应的 PTE。然而，在这种情况中，我们很幸运，TLB 会命中。现在，MMU 有了形成物理地址所需要的所有东西。它通过将来自 PTE 的 PPN（0x0D）和来自虚拟地址的 VPO（0x14）连接起来，这就形成了物理地址（0x354）。

接下来，MMU 发送物理地址给缓存，缓存从物理地址中抽取出缓存偏移 CO（0x0）、缓存组索引 CI（0x5）以及缓存标记 CT（0x0D）。

![img](https://1087580735-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-MHt_spaxGgCbp2POnfq%2F-MIYUko9yvv6aGDarW78%2F-MIYVKDBejaFsLNIo_ja%2F09-20y.png?alt=media&token=a9e1a89b-fd68-4f14-a575-93b32f2fa71e)

因为组 0x5 中的标记与 CT 相匹配，所以缓存检测到一个命中，读出在偏移量 CO 处的数据字节（0x36），并将它返回给 MMU，随后 MMU 将它传递回 CPU。

翻译过程的其他路径也是可能的。例如，如果 TLB 不命中，那么 MMU 必须从页表中的 PTE 中取出 PPN。如果得到的 PTE 是无效的，那么就产生一个缺页，内核必须调入合适的页面，重新运行这条加载指令。另一种可能性是 PTE 是有效的，但是所需要的内存块在缓存中不命中。

### 练习题9.4

说明 9.6.4 节中的示例内存系统是如何将一个虚拟地址翻译成一个物理地址和访问缓存的。对于给定的虚拟地址，指明访问的 TLB 条目、物理地址和返回的缓存字节值。指出是否发生了 TLB 不命中，是否发生了缺页，以及是否发生了缓存不命中。如果是缓存不命中，在“返回的缓存字节”栏中输入 “—”。如果有缺页，则在 “PPN” 一栏中输入 “—”，并且将 C 部分和 D 部分空着。

虚拟地址：0x03d7

A. 虚拟地址格式

![img](https://1087580735-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-MHt_spaxGgCbp2POnfq%2F-MIP9OWkx9VmrN7mxe_h%2F-MIPDO9Lm2qr53q5zDi3%2F09-04 练习题9.4.png?alt=media&token=4ef1f967-286d-4009-8fdf-0ada646cbdac)

00 0011 1101 0111

B. 地址翻译

| 参数                | 值   |
| ------------------- | ---- |
| VPN                 | 0xf  |
| TLB 索引            | 0x3  |
| TLB 标记            | 0x3  |
| TLB 命中？（是/否） | 是   |
| 缺页？（是/否）     | 否   |
| PPN                 | 0xd  |

C. 物理地址格式

![img](https://1087580735-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-MHt_spaxGgCbp2POnfq%2F-MIP9OWkx9VmrN7mxe_h%2F-MIPDp8HUGCwiITU2dLA%2F09-04%20%E7%BB%83%E4%B9%A0%E9%A2%989.4%20%E7%89%A9%E7%90%86%E5%9C%B0%E5%9D%80%E6%A0%BC%E5%BC%8F.png?alt=media&token=a9b0ff65-125a-4b73-b953-1864be390dfd)

0011 0101 0111

D. 物理内存引用

| 参数                | 值   |
| ------------------- | ---- |
| 字节偏移            | 0x3  |
| 缓存索引            | 0x5  |
| 缓存标记            | 0xd  |
| 缓存命中？（是/否） | 是   |
| 返回的缓存字节      | 0x1d |

## 9.7 案例研究：Intel Core i7/Linux内存系统

我们以一个实际系统的案例研究来总结我们对虚拟内存的讨论：一个运行 Linux 的 Intel Core i7。虽然底层的 Haswell 微体系结构允许完全的 64 位虚拟和物理地址空间，而现在的（以及可预见的未来的）Core i7 实现支持 48 位（256 TB）虚拟地址空间和 52 位（4 PB）物理地址空间，还有一个兼容模式，支持 32 位（4 GB）虚拟和物理地址空间。

图 9-21 给出了 Corei7 内存系统的重要部分。**处理器封装**（processor package）包括四个核、一个大的所有核共享的 L3 高速缓存，以及一个 DDR3 内存控制器。每个核包含一个层次结构的 TLB、一个层次结构的数据和指令高速缓存，以及一组快速的点到点链路，这种链路基于 QuickPath 技术，是为了让一个核与其他核和外部 I/O 桥直接通信。TLB 是虚拟寻址的，是四路组相联的。L1、L2 和 L3 高速缓存是物理寻址的，块大小为 64 字节。L1 和 L2 是 8 路组相联的，而 L3 是 16 路组相联的。页大小可以在启动时被配置为 4 KB 或 4 MB。Linux 使用的是 4 KB 的页。

![img](https://1087580735-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-MHt_spaxGgCbp2POnfq%2F-MIYVOlnLH4Fk1ErjsyX%2F-MIYVdFpy4SIVIlNIjIT%2F09-21%20corei7%E7%9A%84%E5%86%85%E5%AD%98%E7%B3%BB%E7%BB%9F.png?alt=media&token=5294a065-d7c6-425a-bb68-5ff7b80d79e1)

> 图 9-21 Core i7 的内存系统

### 9.7.1 Core i7 地址翻译

图 9-22 总结了完整的 Core i7 地址翻译过程，从 CPU 产生虚拟地址的时刻一直到来自内存的数据字到达 CPU。Core i7 采用四级页表层次结构。每个进程有它自己私有的页表层次结构。当一个 Linux 进程在运行时，虽然 Core i7 体系结构允许页表换进换出，但是**与已分配了的页相关联的页表都是驻留在内存中的**。CR3 控制寄存器指向第一级页表（L1）的起始位置。CR3 的值是每个进程上下文的一部分，每次上下文切换时，CR3 的值都会被恢复。

![img](https://1087580735-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-MHt_spaxGgCbp2POnfq%2F-MIYVOlnLH4Fk1ErjsyX%2F-MIYVt6bGlGErtm5CjOE%2F09-22%20corei7%E5%9C%B0%E5%9D%80%E7%BF%BB%E8%AF%91%E7%9A%84%E6%A6%82%E5%86%B5.png?alt=media&token=5be93e67-80e3-48bd-b504-486f42f53a0f)

> 图 9-22 Core i7 地址翻译的概况。为了简化，没有显示 i-cache、i-TLB 和 L2 统一 TLB

图 9-23 给出了第一级、第二级或第三级**页表中条目**的格式。当 P=1时（Linux 中就总是如此），地址字段包含一个 40 位物理页号（PPN），它指向**适当的页表的开始处**。注意，这强加了一个要求，要求物理页表 4 KB 对齐。

![img](https://1087580735-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-MHt_spaxGgCbp2POnfq%2F-MIYVOlnLH4Fk1ErjsyX%2F-MIYWBrM4xpVmchl8U1y%2F09-23%20%E7%AC%AC%E4%B8%80%E7%BA%A7%E3%80%81%E7%AC%AC%E4%BA%8C%E7%BA%A7%E5%92%8C%E7%AC%AC%E4%B8%89%E7%BA%A7%E9%A1%B5%E8%A1%A8%E6%9D%A1%E7%9B%AE%E6%A0%BC%E5%BC%8F.png?alt=media&token=41b8097c-a0f7-4517-9540-75a6fe63e138)

> 图 9-23 第一级、第二级和第三级页表条目格式。每个条目引用一个 4 KB 子页表

图 9-24 给出了第四级页表中条目的格式。当P=1，地址字段包括一个 40 位 PPN，它指向**物理内存中某一页的基地址**。这又强加了一个要求，要求物理页 4 KB 对齐。

![img](https://1087580735-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-MHt_spaxGgCbp2POnfq%2F-MIYVOlnLH4Fk1ErjsyX%2F-MIYWYxtIWHC9MEEjaUs%2F09-24%20%E7%AC%AC%E5%9B%9B%E7%BA%A7%E9%A1%B5%E8%A1%A8%E6%9D%A1%E7%9B%AE%E7%9A%84%E6%A0%BC%E5%BC%8F.png?alt=media&token=0685f4bc-7bd5-4d27-bee7-030b6184961e)

> 图 9-24 第四级页表条目的格式。每个条目引用一个 4 KB 子页

PTE 有三个权限位，控制对页的访问。R/W 位确定页的内容是可以读写的还是只读的。U/S 位确定是否能够在用户模式中访问该页，从而保护操作系统内核中的代码和数据不被用户程序访问。XD（禁止执行）位是在 64 位系统中引入的，可以用来禁止从某些内存页取指令。这是一个重要的新特性，通过限制只能执行只读代码段，使得操作系统内核降低了缓冲区溢出攻击的风险。

当 MMU 翻译每一个虚拟地址时，它还会更新另外两个内核缺页处理程序会用到的位。每次访问一个页时，MMU 都会设置 A 位，称为**引用位**（reference bit）。内核可以用这个引用位来实现它的页替换算法。每次对一个页进行了写之后，MMU 都会设置 D 位，又称**修改位或脏位**（dirty bit）。修改位告诉内核在复制替换页之前是否必须写回牺牲页。内核可以通过调用一条特殊的内核模式指令来清除引用位或修改位。

图 9-25 给出了 Core i7 MMU 如何使用四级的页表来将虚拟地址翻译成物理地址。36 位 VPN 被划分成四个 9 位的片，每个片被用作到一个页表的偏移量。CR3 寄存器包含 L1 页表的物理地址。VPN 1 提供到一个 L1 PTE 的偏移量，这个 PTE 包含 L2 页表的基地址。VPN 2 提供到一个 L2 PTE 的偏移量，以此类推。

![img](https://1087580735-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-MHt_spaxGgCbp2POnfq%2F-MIYVOlnLH4Fk1ErjsyX%2F-MIYWqELXeYPOZmV49bD%2F09-25%20corei7%E9%A1%B5%E8%A1%A8%E7%BF%BB%E8%AF%91.png?alt=media&token=c66f37c7-1832-4e0d-99dc-a8c7911ca677)

> 图 9-25Corei7 页表翻译 
>
> （PT：页表，PTE：页表条目，VPN：虚拟页号，VPO：虚拟页偏移，PPN：物理页号，PPO：物理页偏移量。图中还给出了这四级页表的 Linux 名字）

### 9.7.2 Linux虚拟内存系统

一个虚拟内存系统要求硬件和内核软件之间的紧密协作。版本与版本之间细节都不尽相同，对此完整的阐释超出了我们讨论的范围。但是，在这一小节中我们的目标是对 Linux 的虚拟内存系统做一个描述，使你能够大致了解一个实际的操作系统是如何组织虚拟内存，以及如何处理缺页的。

Linux 为每个进程维护了一个单独的虚拟地址空间，形式如图 9-26 所示。我们已经多次看到过这幅图了，包括它那些熟悉的代码、数据、堆、共享库以及栈段。既然我们理解了地址翻译，就能够填入更多的关于内核虚拟内存的细节了，这部分虚拟内存位于用户栈之上。

![img](https://1087580735-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-MHt_spaxGgCbp2POnfq%2F-MIYVOlnLH4Fk1ErjsyX%2F-MIYX7G66yQxMogQ9LyP%2F09-26%20%E4%B8%80%E4%B8%AAlinux%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98.png?alt=media&token=ae3f2445-f963-4eaa-b4ba-6038539a67e0)

图 9-26 一个 Linux 进程的虚拟内存

内核虚拟内存包含内核中的代码和数据结构。内核虚拟内存的某些区域被映射到所有进程共享的物理页面。例如，每个进程共享内核的代码和全局数据结构。有趣的是，Linux 也将一组连续的虚拟页面（大小等于系统中 DRAM 的总量）映射到相应的一组连续的物理页面。**这就为内核提供了一种便利的方法来访问物理内存中任何特定的位置**，例如，当它需要访问页表，或在一些设备上执行内存映射的 I/。操作，而这些设备被映射到特定的物理内存位置时。

内核虚拟内存的其他区域包含每个进程都不相同的数据。比如说，页表、内核在进程的上下文中执行代码时使用的栈，以及记录虚拟地址空间当前组织的各种数据结构。

#### 1. Linux 虚拟内存区域

Linux 将虚拟内存组织成一些区域（也叫做段）的集合。一个区域（area）就是已经存在着的（已分配的）虚拟内存的连续片（chunk），这些页是以某种方式相关联的。例如，代码段、数据段、堆、共享库段，以及用户栈都是不同的区域。每个存在的虚拟页面都保存在某个区域中，而不属于某个区域的虚拟页是不存在的，并且不能被进程引用。区域的概念很重要，因为它允许虚拟地址空间有间隙。**内核不用记录那些不存在的虚拟页**，而这样的页也不占用内存、磁盘或者内核本身中的任何额外资源。

图 9-27 强调了记录一个进程中虚拟内存区域的内核数据结构。内核为系统中的每个进程维护一个单独的任务结构（源代码中的 task_struct）。任务结构中的元素包含或者指向内核运行该进程所需要的所有信息（例如，PID、指向用户栈的指针、可执行目标文件的名字，以及程序计数器）。

![img](https://1087580735-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-MHt_spaxGgCbp2POnfq%2F-MIYXCLnKQ6f8Y605q-O%2F-MIYXNaTtkJTfH1JXL6A%2F09-27%20linux%E6%98%AF%E5%A6%82%E4%BD%95%E7%BB%84%E7%BB%87%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E7%9A%84.png?alt=media&token=dfbf74d8-b756-406f-bb30-c2f5f85fe801)

> 图 9-27 Linux 是如何组织虚拟内存的

任务结构中的一个条目指向 mm_struct，它描述了虚拟内存的当前状态。我们感兴趣的两个字段是 pgd 和 mmap，其中 pgd 指向第一级页表（页全局目录）的基址，而 mmap 指向一个 vm_area_structs（区域结构）的链表，其中每个 vm_area_structs 都描述了当前虚拟地址空间的一个区域。当内核运行这个进程时，就将 pgd 存放在 CR3 控制寄存器中。

为了我们的目的，一个具体区域的区域结构包含下面的字段：

- vm_start：指向这个区域的起始处。
- vm_end：指向这个区域的结束处。
- vm_prot：描述这个区域内包含的所有页的读写许可权限。
- vm_flags：描述这个区域内的页面是与其他进程共享的，还是这个进程私有的（还描述了其他一些信息）。
- vm_next：指向链表中下—区域结构。

#### 2. Linux 缺页异常处理

假设 MMU 在试图翻译某个虚拟地址 A 时，触发了一个缺页。这个异常导致控制转移到内核的缺页处理程序，处理程序随后就执行下面的步骤：

1. **虚拟地址 A 是合法的吗？**换句话说，A 在某个区域结构定义的区域内吗？为了回答这个问题，缺页处理程序搜索区域结构的链表，把 A 和每个区域结构中的 vm_start 和 vm_end 做比较。如果这个指令是不合法的，那么缺页处理程序就触发一个段错误，从而终止这个进程。这个情况在图 9-28 中标识为 “1”。

   因为一个进程可以创建任意数量的新虚拟内存区域（使用在下一节中描述的 mmap 函数），所以顺序搜索区域结构的链表花销可能会很大。因此在实际中，Linux 使用某些我们没有显示出来的字段，Linux 在链表中构建了一棵树，并在这棵树上进行查找。

2. **试图进行的内存访问是否合法？**换句话说，进程是否有读、写或者执行这个区域内页面的权限？例如，这个缺页是不是由一条试图对这个代码段里的只读页面进行写操作的存储指令造成的？这个缺页是不是因为一个运行在用户模式中的进程试图从内核虚拟内存中读取字造成的？如果试图进行的访问是不合法的，那么缺页处理程序会触发一个保护异常，从而终止这个进程。这种情况在图 9-28 中标识为 “2”。

3. **此刻，内核知道了这个缺页是由于对合法的虚拟地址进行合法的操作造成的。**它是这样来处理这个缺页的：选择一个牺牲页面，如果这个牺牲页面被修改过，那么就将它交换出去，换入新的页面并更新页表。当缺页处理程序返回时，CPU 重新启动引起缺页的指令，这条指令将再次发送 A 到 MMU。这次，MMU 就能正常地翻译 A，而不会再产生缺页中断了。

![img](https://1087580735-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-MHt_spaxGgCbp2POnfq%2F-MIYXCLnKQ6f8Y605q-O%2F-MIYXcW9ffVZKHEsohzk%2F09-28%20linux%E7%BC%BA%E9%A1%B5%E5%A4%84%E7%90%86.png?alt=media&token=6fc05c04-f53a-4974-aa58-cc0e4ea4db16)

> 图 9-28 Linux 缺页处理

## 9.8 内存映射

Linux 通过将一个虚拟内存区域与一个磁盘上的**对象**（object）关联起来，以初始化这个虚拟内存区域的内容，这个过程称为**内存映射**（memory mapping），虚拟内存区域可以映射到两种类型的对象中的一种：

1. **Linux 文件系统中的普通文件：**一个区域可以映射到一个普通磁盘文件的连续部分，例如一个可执行目标文件。文件区（section）被分成页大小的片，每一片包含一个虚拟页面的初始内容。因为按需进行页面调度，所以这些虚拟页面没有实际交换进入物理内存，直到 CPU 第一次引用到页面（即发射一个虚拟地址，落在地址空间这个页面的范围之内）。如果区域比文件区要大，那么就用零来填充这个区域的余下部分。
2. **匿名文件：**一个区域也可以映射到一个匿名文件，匿名文件是由内核创建的，包含的全是二进制零。CPU 第一次引用这样一个区域内的虚拟页面时，内核就在物理内存中找到一个合适的牺牲页面，如果该页面被修改过，就将这个页面换出来，用二进制零覆盖牺牲页面并更新页表，将这个页面标记为是驻留在内存中的。注意在磁盘和内存之间并没有实际的数据传送。因为这个原因，映射到匿名文件的区域中的页面有时也叫做请**求二进制零的页**（demand-zero page）。

无论在哪种情况中，一旦一个虚拟页面被初始化了，它就在一个由内核维护的专门的**交换文件**（swap file）之间换来换去。交换文件也叫做**交换空间**（swap space）或者**交换区域**（swap area）。需要意识到的很重要的一点是，在任何时刻，交换空间都限制着当前运行着的进程能够分配的虚拟页面的总数。

### 9.8.1 再看共享对象

内存映射的概念来源于一个聪明的发现：如果虚拟内存系统可以集成到传统的文件系统中，那么就能提供一种简单而高效的把程序和数据加载到内存中的方法。

正如我们已经看到的，进程这一抽象能够为每个进程提供自己私有的虚拟地址空间，可以免受其他进程的错误读写。不过，许多进程有同样的只读代码区域。例如，每个运行 Linux shell 程序 bash 的进程都有相同的代码区域。而且，许多程序需要访问只读运行时库代码的相同副本。例如，每个 C 程序都需要来自标准 C 库的诸如 printf 这样的函数。那么，如果每个进程都在物理内存中保持这些常用代码的副本，那就是极端的浪费了。幸运的是，内存映射给我们提供了一种清晰的机制，用来控制多个进程如何共享对象。

一个对象可以被映射到虚拟内存的一个区域，要么作为共享对象，要么作为私有对象。如果一个进程将一个共享对象映射到它的虚拟地址空间的一个区域内，那么这个进程对这个区域的任何写操作，对于那些也把这个共享对象映射到它们虚拟内存的其他进程而言，也是可见的。而且，这些变化也会反映在磁盘上的原始对象中。

另一方面，对于一个映射到私有对象的区域做的改变，对于其他进程来说是不可见的，并且进程对这个区域所做的任何写操作都不会反映在磁盘上的对象中。一个映射到共享对象的虚拟内存区域叫做**共享区域**。类似地，也有**私有区域**。

假设进程 1 将一个共享对象映射到它的虚拟内存的一个区域中，如图 9-29a 所示。现在假设进程 2 将同一个共享对象映射到它的地址空间（并不一定要和进程 1 在相同的虚拟地址处，如图 9-29b 所示）。

![img](https://1087580735-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-MHt_spaxGgCbp2POnfq%2F-MIYXgV_34xHHD8v3VJ-%2F-MIYc8po2IKUtT6073Ip%2F09-29%20%E4%B8%80%E4%B8%AA%E5%85%B1%E4%BA%AB%E5%AF%B9%E8%B1%A1.png?alt=media&token=771f87f9-d451-492c-8d94-8d0d61e6dceb)

> 图 9-29 一个共享对象（注意，物理页面不一定是连续的）

因为每个对象都有一个唯一的文件名，内核可以迅速地判定进程 1 已经映射了这个对象，而且可以使进程 2 中的页表条目指向相应的物理页面。关键点在于即使对象被映射到了多个共享区域，物理内存中也只需要存放共享对象的一个副本。为了方便，我们将物理页面显示为连续的，但是在一般情况下当然不是这样的。

私有对象使用一种叫做**写时复制**（copy-on-write）的巧妙技术被映射到虚拟内存中。一个私有对象开始生命周期的方式基本上与共享对象的一样，在物理内存中只保存有私有对象的一份副本。比如，图 9-30a 展示了一种情况，其中两个进程将一个私有对象映射到它们虚拟内存的不同区域，但是共享这个对象同一个物理副本。对于每个映射私有对象的进程，相应私有区域的页表条目都被标记为只读，并且区域结构被标记为私有的写时复制。只要没有进程试图写它自己的私有区域，它们就可以继续共享物理内存中对象的一个单独副本。然而，只要有一个进程试图写私有区域内的某个页面，那么这个写操作就会触发一个保护故障。

![img](https://1087580735-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-MHt_spaxGgCbp2POnfq%2F-MIYXgV_34xHHD8v3VJ-%2F-MIYcQzbJ1WVOzu18dlQ%2F09-30%20%E4%B8%80%E4%B8%AA%E7%A7%81%E6%9C%89%E7%9A%84%E5%86%99%E6%97%B6%E5%A4%8D%E5%88%B6%E5%AF%B9%E8%B1%A1.png?alt=media&token=aacf0b5f-f662-46a7-8253-852589ad89ba)

> 图 9-30 一个私有的写时复制对象

当故障处理程序注意到保护异常是由于进程试图写私有的写时复制区域中的一个页面而引起的，它就会在物理内存中创建这个页面的一个新副本，更新页表条目指向这个新的副本，然后恢复这个页面的可写权限，如图 9-30b 所示。当故障处理程序返回时，CPU 重新执行这个写操作，现在在新创建的页面上这个写操作就可以正常执行了。

通过延迟私有对象中的副本直到最后可能的时刻，写时复制最充分地使用了稀有的物理内存。

### 9.8.2 再看 fork 函数

既然我们理解了虚拟内存和内存映射，那么我们可以清晰地知道 fork 函数是如何创建一个带有自己独立虚拟地址空间的新进程的。

当 fork 函数被当前进程调用时，内核为新进程创建各种数据结构，并分配给它一个唯一的 PID。为了给这个新进程创建虚拟内存，它创建了当前进程的 mm_struct、区域结构和页表的原样副本。它将两个进程中的每个页面都标记为只读，并将两个进程中的每个区域结构都标记为私有的写时复制。

当 fork 在新进程中返回时，新进程现在的虚拟内存刚好和调用 fork 时存在的虚拟内存相同。当这两个进程中的任一个后来进行写操作时，写时复制机制就会创建新页面，因此，也就为每个进程保持了私有地址空间的抽象概念。

### 9.8.3 再看 execve 函数

虚拟内存和内存映射在将程序加载到内存的过程中也扮演着关键的角色。既然已经理解了这些概念，我们就能够理解 execve 函数实际上是如何加载和执行程序的。假设运行在当前进程中的程序执行了如下的 execve 调用：

```c
execve("a.out", NULL, NULL);
```

正如在第 8 章中学到的，execve 函数在当前进程中加载并运行包含在可执行目标文件 a.out 中的程序，用 a.out 程序有效地替代了当前程序。加载并运行 a.out 需要以下几个步骤：

1. **删除已存在的用户区域。**删除当前进程虚拟地址的用户部分中的已存在的区域结构。
2. **映射私有区域。**为新程序的代码、数据、bss 和栈区域创建新的区域结构。所有这些新的区域都是私有的、写时复制的。代码和数据区域被映射为 a.out 文件中的. text 和. data 区。bss 区域是请求二进制零的，映射到匿名文件，其大小包含在 a.out 中。栈和堆区域也是请求二进制零的，初始长度为零。图 9-31 概括了私有区域的不同映射。
3. **映射共享区域。**如果 a.out 程序与共享对象（或目标）链接，比如标准 C 库 libc.so，那么这些对象都是动态链接到这个程序的，然后再映射到用户虚拟地址空间中的共享区域内。
4. **设置程序计数器（PC）。**execve 做的最后一件事情就是设置当前进程上下文中的程序计数器，使之指向代码区域的入口点。

![img](https://1087580735-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-MHt_spaxGgCbp2POnfq%2F-MIYXgV_34xHHD8v3VJ-%2F-MIYceiWSapZXPJFeiyj%2F09-31%20%E5%8A%A0%E8%BD%BD%E5%99%A8%E6%98%AF%E5%A6%82%E4%BD%95%E6%98%A0%E5%B0%84%E7%94%A8%E6%88%B7%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4%E7%9A%84%E5%8C%BA%E5%9F%9F%E7%9A%84.png?alt=media&token=220979b9-e0a1-45e6-b8fc-d0c727568a97)

图 9-31 加载器是如何映射用户地址空间的区域的

下一次调度这个进程时，它将从这个入口点开始执行。Linux 将根据需要换入代码和数据页面。

```c
#include <unistd.h>
#include <sys/mman.h>

void *mmap(void *start, size_t length, int prot, int flags,
           int fd, off_t offset);

// 返回：若成功时则为指向映射区域的指针，若出错则为 MAP_FAILED(-1)。
```

mmap 函数要求内核创建一个新的虚拟内存区域，最好是从地址 start 开始的一个区域，并将文件描述符 fd 指定的对象的一个连续的片（chunk）映射到这个新的区域。连续的对象片大小为 length 字节，从距文件开始处偏移量为 offset 字节的地方开始。start 地址仅仅是一个暗示，通常被定义为 NULL。为了我们的目的，我们总是假设起始地址为 NULL。图 9-32 描述了这些参数的意义。

![img](https://1087580735-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-MHt_spaxGgCbp2POnfq%2F-MIYXgV_34xHHD8v3VJ-%2F-MIYcsgIfwEYwEaDTr9t%2F09-32%20mmap%E5%8F%82%E6%95%B0%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E8%A7%A3%E9%87%8A.png?alt=media&token=4448a604-0947-49da-913f-9539c57757a0)

> 图 9-32 mmap 参数的可视化解释

参数 prot 包含描述新映射的虚拟内存区域的访问权限位（即在相应区域结构中的 vm_prot 位）。

- **PROT_EXEC：**这个区域内的页面由可以被 CPU 执行的指令组成。
- **PROT_READ：**这个区域内的页面可读。
- **PROT_WRITE：**这个区域内的页面可写。
- **PROT_NONE：**这个区域内的页面不能被访问。

参数 flags 由描述被映射对象类型的位组成。如果设置了 MAP_ANON 标记位，那么被映射的对象就是一个匿名对象，而相应的虚拟页面是请求二进制零的。MAP_PRI-VATE 表示被映射的对象是一个私有的、写时复制的对象，而 MAP_SHARED 表示是一个共享对象。例如

```c
bufp = Mmap(NULL, size, PROT_READ, MAP_PRIVATE|MAP_ANON, 0, 0);
```

让内核创建一个新的包含 size 字节的只读、私有、请求二进制零的虚拟内存区域。如果调用成功，那么 bufp 包含新区域的地址。

munmap 函数删除虚拟内存的区域：

```c
#include <unistd.h>
#include <sys/mman.h>

int munmap(void *start, size_t length);

// 返回：若成功则为 0，若出错则为 -1。
```

munmap 函数删除从虚拟地址 start 开始的，由接下来 length 字节组成的区域。接下来对已删除区域的引用会导致段错误。

### 练习题9.5

编写一个 C 程序 mmapcopy.c，使用 mmap 将一个任意大小的磁盘文件复制到 stdout, 输入文件的名字必须作为一个命令行参数来传递。

解决这个题目将帮助你很好地理解内存映射。请自己独立完成这道题。我们没有讨论 open、fstat 或者 write 函数，所以你需要阅读它们的帮助页来看看它们是如何工作的。

```c
#include "csapp.h"

/*
* mmapcopy - uses mmap to copy file fd to stdout
*/
void mmapcopy(int fd, int size)
{
    char *bufp; /* ptr to memory-mapped VM area */

    bufp = Mmap(NULL, size, PROT_READ, MAP_PRIVATE, fd, 0);
    Write(1, bufp, size);
    return;
}

/* mmapcopy driver */
int main(int argc, char **argv)
{
    struct stat stat;
    int fd;

    /* Check for required command-line argument */
    if (argc != 2) {
        printf("usage: %s <filename>\n", argv[0]);
        exit(0);
    }

    /* Copy the input argument to stdout */
    fd = Open(argv[1], O_RDONLY, 0);
    fstat(fd, &stat);
    mmapcopy(fd, stat.st_size);
    exit(0);
}
```

## 9.9 动态内存分配

一个动态存储器分配器维护着一个进程的虚拟存储器区域，称为堆（heap）。

[![enter description here](https://data2.liuin.cn/story-writer/2018_1_31_1517405624725.jpg)](https://data2.liuin.cn/story-writer/2018_1_31_1517405624725.jpg)

显式分配器要求应用显式地释放任何已经分配的块

隐式分配器要求检测何时一个已分配块不再被使用，然后就释放这个块。隐式分配器也叫做垃圾收集器（garbage collector）

### 9.8.1 为什么要使用动态存储器分配

经常直到程序运行时，才知道某些数据结构的大小

### 9.8.2 碎片

造成堆利用率低的主要原因是碎片（fragmentation），当虽然有未使用的存储器但是不能用来满足分配请求时，就发生这种现象。有两种碎片形式：**内部碎片**（internal fragmentation）和**外部碎片**（external fragmentation）：

- 内部碎片是在一个已分配块比有效载荷大时发生的。
- 外部碎片是当空闲存储器合计起来足够满足一个分配请求，但是没有一个单独的空闲块足够大可以来处理这个请求时发生的。

## 9.10 垃圾收集

垃圾收集器（garbage collector）是一种动态存储分配器，它自动释放程序不在需要的已分配块。

### 9.9.1 垃圾收集器的基本要素

垃圾收集器将存储器视为一张有向可达图（reachability graph）

[![enter description here](https://data2.liuin.cn/story-writer/2018_1_31_1517406251592.jpg)](https://data2.liuin.cn/story-writer/2018_1_31_1517406251592.jpg)

## 9.11 C程序中常见的与存储器相关的错误

- 间接引用坏指针
- 读未初始化的存储器
- 允许栈缓冲区溢出
- 假设指针和他们指向的对象是相同大小的
- 造成错位错误
- 引用指针而不是他们指向的对象
- 误解指针运算
- 引用不存在的变量
- 引用空闲堆块中的数据
- 引起存储器泄露

## 9.12 小结

虚拟存储器是对主存的一个抽象，支持虚拟存储器的处理器通过一种叫做虚拟寻址的间接引用来引用主存